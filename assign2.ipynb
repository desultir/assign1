{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assign2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/desultir/assign1/blob/master/assign2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNETLdx3NYsT",
        "colab_type": "code",
        "outputId": "a36c8b08-0c9f-49b0-d3c1-d7ff62cb6c8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "  \n",
        "#!cd \"/content/drive/My Drive/Colab Notebooks/PretrainedModels\" && tar xvzf *.tar.gz\n",
        "#!cd \"/content/drive/My Drive/Colab Notebooks/Input\" && tar xvzf test.tar.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-pL_iRxK-E_",
        "colab_type": "code",
        "outputId": "6c960da6-1d84-483f-ee68-67ea7b9bf057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "#install tensorboard tunnel\n",
        "#https://www.dlology.com/blog/quick-guide-to-run-tensorboard-in-google-colab/\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-14 07:43:07--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.207.111.186, 34.206.9.96, 52.203.66.95, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.207.111.186|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16529980 (16M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.3’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  15.76M  15.5MB/s    in 1.0s    \n",
            "\n",
            "2019-05-14 07:43:08 (15.5 MB/s) - ‘ngrok-stable-linux-amd64.zip.3’ saved [16529980/16529980]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: asd\n",
            "error:  invalid response [asd]\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: er\n",
            "error:  invalid response [er]\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: xzc\n",
            "error:  invalid response [xzc]\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: asd\n",
            "error:  invalid response [asd]\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le9tHatGFym_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_DIR = \"/content/drive/My Drive/Colab Notebooks/PretrainedModels/\"\n",
        "MODEL_NAME = \"faster_rcnn_resnet50_coco_2018_01_28\"\n",
        "\n",
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTgfA-2mLPde",
        "colab_type": "code",
        "outputId": "81b7e5ba-b0bd-41fe-c9b8-69dc918a2d0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://506bbc08.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot5mOjEzjmLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib.image import imread\n",
        "import PIL.Image\n",
        "from PIL import ImageOps\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "def normalize_image(rgb):\n",
        "  white_rgb = rgb - np.mean(rgb)\n",
        "  white_rgb = white_rgb / np.max(np.abs(white_rgb))\n",
        "  return white_rgb\n",
        "\n",
        "def decompress_expand(jpg):\n",
        "  #zero pad to 320x320\n",
        "  encoded_jpg_io = io.BytesIO(jpg)\n",
        "  image = PIL.Image.open(encoded_jpg_io)\n",
        "  DESIRED_SIZE = 320\n",
        "  widthpad = (DESIRED_SIZE - image.width)\n",
        "  heightpad = (DESIRED_SIZE - image.height)\n",
        "  padding = (widthpad//2, heightpad//2, widthpad - widthpad//2, heightpad-heightpad//2)\n",
        "  padded = ImageOps.expand(image, padding)\n",
        "  return padded\n",
        "\n",
        "\n",
        "def load_and_preprocess(path):\n",
        "  with tf.gfile.GFile(path, 'rb') as fp:\n",
        "    jpg = fp.read()\n",
        "  return decompress_expand(jpg)\n",
        "\n",
        "def load_np(paths):\n",
        "  return np.stack([imread(x) for x in paths])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icyq6f23O4nQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.core.framework import graph_pb2\n",
        "from tensorflow.python.saved_model import loader\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "#load train images\n",
        "train_img_list = glob.glob(r\"/content/drive/My Drive/Colab Notebooks/Input/train2014/*.jpg\")\n",
        "image_list = list(map(load_and_preprocess, train_img_list[:30]))\n",
        "#train_img_list_ds = tf.data.Dataset.from_tensor_slices(image_list)\n",
        "#load train labels\n",
        "train_labels_filename = r\"/content/drive/My Drive/Colab Notebooks/Input/train.txt\"\n",
        "with open(train_labels_filename) as f:\n",
        "  reader = csv.reader(f, delimiter='\\t')\n",
        "  train_labels = {k:v for k, v in reader}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHtgiCtnSbxX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "38dc5c18-ab5b-4e9b-d66a-8d00a5bd9cd9"
      },
      "source": [
        "#load the trainable model from the checkpoint\n",
        "sess = tf.Session()\n",
        "\n",
        "saver = tf.train.import_meta_graph(os.path.join(MODEL_DIR,MODEL_NAME, 'model.ckpt.meta'))\n",
        "class_weights = tf.get_variable(\"SecondStageBoxPredictor/ClassPredictor/weights\", shape=(2048, 91), trainable=True)\n",
        "class_bias = tf.get_variable(\"SecondStageBoxPredictor/ClassPredictor/biases\", shape=(91), trainable=True)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "saver.restore(sess, os.path.join(MODEL_DIR,MODEL_NAME, 'model.ckpt'))\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f5598f67d5b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model.ckpt.meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SecondStageBoxPredictor/ClassPredictor/weights\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m91\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mclass_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SecondStageBoxPredictor/ClassPredictor/biases\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m91\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1477\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1218\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m   def _get_partitioned_variable(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    545\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m   def _get_partitioned_variable(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    497\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"tensorflow/python\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" % (err_msg, \"\".join(\n\u001b[0;32m--> 848\u001b[0;31m             traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    849\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Variable SecondStageBoxPredictor/ClassPredictor/weights already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-8-e9008beefc88>\", line 4, in <module>\n    tf.get_variable(\"SecondStageBoxPredictor/ClassPredictor/weights\", shape=(2048, 91), trainable=True)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rlRv19rBI5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write graph for tensorboard\n",
        "summary_writer = tf.summary.FileWriter(LOG_DIR, sess.graph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VdqsxxXF3Hg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hG0eObOVFUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "98b89b07-6f6c-4273-c75c-868064b2b2e6"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.04742658,  0.03711859,  0.02226122, ..., -0.01608155,\n",
              "        -0.01137163,  0.04715434],\n",
              "       [ 0.00854041,  0.01166996,  0.04419908, ..., -0.04339767,\n",
              "         0.02548472,  0.03276471],\n",
              "       [ 0.01782445,  0.01630704, -0.00773155, ..., -0.03172974,\n",
              "         0.00012942,  0.04512846],\n",
              "       ...,\n",
              "       [-0.03842142,  0.03758601,  0.01248769, ...,  0.01527385,\n",
              "         0.03815636,  0.01854701],\n",
              "       [-0.01291022, -0.0181416 , -0.00447982, ..., -0.05214845,\n",
              "        -0.01356228, -0.03405831],\n",
              "       [ 0.00751096,  0.02897915,  0.01423248, ...,  0.03020339,\n",
              "        -0.03240707, -0.00874436]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS2bPDzwufSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stacked_imgs = np.stack(image_list)\n",
        "#result = sess.run((\"detection_classes:0\", \"detection_scores:0\"), feed_dict={\"image_tensor:0\": stacked_imgs})\n",
        "\n",
        "result = sess.run((\"SecondStagePostprocessor/convert_scores:0\", \"detection_classes:0\", \"num_detections:0\"), feed_dict={\"image_tensor:0\": stacked_imgs})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdxGbqfBwpf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import stats\n",
        "#np.argmax(result[0][3][:,3]) # prediction\n",
        "#result[0][3] #prediction\n",
        "preds = np.argmax(result[0], axis=2)\n",
        "#result[1][3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6dMjsLRcuh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result[1][3] # classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRmaJRN42QiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class relabeler(object):\n",
        "  def __init__(self):\n",
        "    self.labels = {}\n",
        "     #mapping from cocolabel to tutorlabel + 1 (0 reserved for 'reject bounding box')\n",
        "    self.labels[9] = 1 #boat \n",
        "    self.labels[10] = 5 #traffic light \n",
        "    self.labels[14] = 6 #parking meter\n",
        "    self.labels[15] = 7 #bench\n",
        "    self.labels[16] = 18 #bird\n",
        "    self.labels[36] = 2 #snowboard\n",
        "    self.labels[39] = 4 #baseball bat\n",
        "    self.labels[41] = 3 #skateboard\n",
        "    self.labels[44] = 10 #bottle\n",
        "    self.labels[49] = 9 #knife\n",
        "    self.labels[50] = 8 #spoon\n",
        "    self.labels[52] = 15 #banana\n",
        "    self.labels[54] = 13 #sandwich\n",
        "    self.labels[57] = 14 #carrot\n",
        "    self.labels[79] = 17 #oven\n",
        "    self.labels[80] = 16 #toaster\n",
        "    self.labels[85] = 12 #clock\n",
        "    self.labels[90] = 11 #toothbrush   \n",
        "    \n",
        "  def fix(self, old):\n",
        "    return self.labels.get(old, 0)\n",
        "  \n",
        "  def get_fix_fn(self):\n",
        "    return np.vectorize(self.fix)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VaczoEGuGNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_pl = tf.placeholder(tf.int32, [None, 1], name='labels')\n",
        "#mapping from ben\n",
        "fixfn = relabeler().get_fix_fn()\n",
        "labels = fixfn(preds)\n",
        "#TODO add mean here if batch training\n",
        "loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=sess.graph.get_tensor_by_name(\"SecondStagePostprocessor/convert_scores:0\"), labels=label_pl)\n",
        "\n",
        "# Train op\n",
        "with tf.name_scope(\"train\"):\n",
        "    # Get gradients of all trainable variables\n",
        "    # TODO actually pass vars in, not their names\n",
        "    var_list = [class_weights, class_biases]\n",
        "    gradients = tf.gradients(loss, var_list)\n",
        "    gradients = list(zip(gradients, var_list))\n",
        "    learning_rate = 0.01\n",
        "\n",
        "    # Create optimizer and apply gradient descent to the trainable variables\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "    train_op = optimizer.apply_gradients(grads_and_vars=gradients)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJHWakmQ0FEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.graph.get_tensor_by_name(\"SecondStageBoxPredictor/ClassPredictor/weights:0\")\n",
        "#sess.graph.get_operation_by_name(\"SecondStageBoxPredictor/ClassPredictor/weights\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZyHcLyndJCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNrJljshSMpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fctn15JdKrwp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}