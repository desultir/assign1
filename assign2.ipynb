{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assign2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/desultir/assign1/blob/master/assign2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNETLdx3NYsT",
        "colab_type": "code",
        "outputId": "fd095553-ae12-4d0f-b94e-6241fc826bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "  \n",
        "#!cd \"/content/drive/My Drive/Colab Notebooks/PretrainedModels\" && tar xvzf *.tar.gz\n",
        "#!cd \"/content/drive/My Drive/Colab Notebooks/Input\" && tar xvzf test.tar.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-pL_iRxK-E_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "f0f30c2a-9383-4d01-cd1f-d10b6376818e"
      },
      "source": [
        "#install tensorboard tunnel\n",
        "#https://www.dlology.com/blog/quick-guide-to-run-tensorboard-in-google-colab/\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "#!cd \"/content/drive/My Drive/Colab Notebooks/Input/val2014\" && cp * ../../LabelingVal/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-23 03:17:10--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.7.169.168, 34.206.130.40, 52.4.95.48, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.7.169.168|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16648024 (16M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  15.88M  38.4MB/s    in 0.4s    \n",
            "\n",
            "2019-05-23 03:17:11 (38.4 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [16648024/16648024]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le9tHatGFym_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_DIR = \"/content/drive/My Drive/Colab Notebooks/PretrainedModels/\"\n",
        "MODEL_NAME = \"faster_rcnn_resnet50_coco_2018_01_28\"\n",
        "\n",
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTgfA-2mLPde",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b633d21-b120-480a-c00f-72673c8cd182"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://1a166d8b.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot5mOjEzjmLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib.image import imread\n",
        "import PIL.Image\n",
        "from PIL import ImageOps\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "def normalize_image(rgb):\n",
        "  white_rgb = rgb - np.mean(rgb)\n",
        "  white_rgb = white_rgb / np.max(np.abs(white_rgb))\n",
        "  return white_rgb\n",
        "\n",
        "def decompress_expand(jpg):\n",
        "  #zero pad to 320x320\n",
        "  encoded_jpg_io = io.BytesIO(jpg)\n",
        "  image = PIL.Image.open(encoded_jpg_io)\n",
        "  DESIRED_SIZE = 320\n",
        "  widthpad = (DESIRED_SIZE - image.width)\n",
        "  heightpad = (DESIRED_SIZE - image.height)\n",
        "  padding = (widthpad//2, heightpad//2, widthpad - widthpad//2, heightpad-heightpad//2)\n",
        "  padded = ImageOps.expand(image, padding)\n",
        "  return padded\n",
        "\n",
        "\n",
        "def load_and_preprocess(path):\n",
        "  with tf.gfile.GFile(path, 'rb') as fp:\n",
        "    jpg = fp.read()\n",
        "  return decompress_expand(jpg)\n",
        "\n",
        "def load_np(paths):\n",
        "  return np.stack([imread(x) for x in paths])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icyq6f23O4nQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.core.framework import graph_pb2\n",
        "from tensorflow.python.saved_model import loader\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "NUM_TRAINING = 31924\n",
        "\n",
        "#load train images\n",
        "def get_training_images(split=False):\n",
        "  #train_img_list = glob.glob(r\"/content/drive/My Drive/Colab Notebooks/Input/train2014/*.jpg\")\n",
        "  train_img_list = [\"/content/drive/My Drive/Colab Notebooks/Input/train2014/{}.jpg\".format(i) for i in range(31924)]\n",
        "  if not split:\n",
        "    return train_img_list\n",
        "  else:\n",
        "    np.random.seed(1)\n",
        "    np.random.shuffle(train_img_list)\n",
        "    # 90/10 split\n",
        "    split_pt = (NUM_TRAINING // 10) * 9\n",
        "    return train_img_list[:split_pt], train_img_list[split_pt:]\n",
        "\n",
        "#train_img_list_ds = tf.data.Dataset.from_tensor_slices(image_list)\n",
        "#load train labels\n",
        "train_labels_filename = r\"/content/drive/My Drive/Colab Notebooks/Input/train.txt\"\n",
        "with open(train_labels_filename) as f:\n",
        "  reader = csv.reader(f, delimiter='\\t')\n",
        "  train_labels = {k:list(map(int, v.split(','))) for k, v in reader}\n",
        "  \n",
        "def get_label(filename):\n",
        "  if '/' in filename:\n",
        "    filename = filename.rsplit('/', 1)[-1]\n",
        "  return train_labels.get(filename)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdW0_Jjxb1Fi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHtgiCtnSbxX",
        "colab_type": "code",
        "outputId": "17480bf7-73ca-4bd7-9f37-06a3516eff63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "#load the trainable model from the checkpoint\n",
        "sess = tf.Session()\n",
        "\n",
        "saver = tf.train.import_meta_graph(os.path.join(MODEL_DIR,MODEL_NAME, 'model.ckpt.meta'))\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "saver.restore(sess, os.path.join(MODEL_DIR,MODEL_NAME, 'model.ckpt'))\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Colab Notebooks/PretrainedModels/faster_rcnn_resnet50_coco_2018_01_28/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rlRv19rBI5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write graph for tensorboard\n",
        "summary_writer = tf.summary.FileWriter(LOG_DIR, sess.graph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS2bPDzwufSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#PREDICTION\n",
        "BATCH_SIZE = 10\n",
        "batch_no = 0\n",
        "batch_list = []\n",
        "result_list = []\n",
        "while image_list:\n",
        "  try:\n",
        "    while len(batch_list) < BATCH_SIZE:\n",
        "      batch_list.append(next(image_list))\n",
        "  except StopIteration:\n",
        "    pass\n",
        "  stacked_imgs = np.stack(batch_list)\n",
        "  batch_result = sess.run((\"detection_classes:0\", \"detection_scores:0\"), feed_dict={\"image_tensor:0\": stacked_imgs})\n",
        "  batch_list = []\n",
        "  batch_no += 1\n",
        "  print(batch_no)\n",
        "  result_list.append(batch_result)\n",
        "  \n",
        "  \n",
        "#result = sess.run((\"SecondStagePostprocessor/convert_scores:0\", \"detection_classes:0\", \"num_detections:0\"), feed_dict={\"image_tensor:0\": stacked_imgs})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXqJ0yI8Zu4H",
        "colab_type": "code",
        "outputId": "4ba5228e-c3de-45e2-ac53-0ccc253867ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "import pickle\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/full_results.pk\", 'wb') as f:\n",
        "  pickle.dump(result_list, f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-65c55b22cf33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mprinytprinyprinytpriprinytprinyprinytpprinytprinyprinytpriprinytprinypriny\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'prinytprinyprinytpriprinytprinyprinytpprinytprinyprinytpriprinytprinypriny' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRmaJRN42QiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class relabeler(object):\n",
        "  def __init__(self):\n",
        "    self.labels = {}\n",
        "     #mapping from cocolabel to tutorlabel + 1 (0 reserved for 'reject bounding box')\n",
        "    self.labels[9] = 1 #boat \n",
        "    self.labels[10] = 5 #traffic light \n",
        "    self.labels[14] = 6 #parking meter\n",
        "    self.labels[15] = 7 #bench\n",
        "    self.labels[16] = 18 #bird\n",
        "    self.labels[28] = 19 #umbrella\n",
        "    self.labels[31] = 20 #handbag\n",
        "    self.labels[36] = 2 #snowboard\n",
        "    self.labels[39] = 4 #baseball bat\n",
        "    self.labels[41] = 3 #skateboard\n",
        "    self.labels[44] = 10 #bottle\n",
        "    self.labels[49] = 9 #knife\n",
        "    self.labels[50] = 8 #spoon\n",
        "    self.labels[52] = 15 #banana\n",
        "    self.labels[54] = 13 #sandwich\n",
        "    self.labels[57] = 14 #carrot\n",
        "    self.labels[79] = 17 #oven\n",
        "    self.labels[80] = 16 #toaster\n",
        "    self.labels[85] = 12 #clock\n",
        "    self.labels[90] = 11 #toothbrush   \n",
        "    self.fix_fn = self.get_fix_fn()\n",
        "    \n",
        "  def fix(self, old):\n",
        "    return self.labels.get(old, 0)\n",
        "  \n",
        "  def get_fix_fn(self):\n",
        "    return np.vectorize(self.fix)\n",
        "    \n",
        "  def get_best_label(self, preds):\n",
        "    #convert to new label space and get best label\n",
        "    labels = self.fix_fn(preds)\n",
        "    #return labels\n",
        "    #return first that isn't 0\n",
        "    if len(np.nonzero(labels)[0]):\n",
        "      return labels[np.nonzero(labels)[0][0]] - 1 #shift back into original label space\n",
        "    else:\n",
        "      return 19 #-1 handbag is the thing we most frequently fail at "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u51rjaFk5vDt",
        "colab_type": "code",
        "outputId": "2e284cfc-74ac-4a75-81e0-85f7d0d0d3fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pickle\n",
        "#unpickle resulst file\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/full_results.pk\", 'rb') as f:\n",
        "  results_list = pickle.load(f)\n",
        "  \n",
        "len(results_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv7iXHMb-vJW",
        "colab_type": "code",
        "outputId": "a60f094c-6b53-42e4-c334-dab2e563ac66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "results = [x[0] for x in results_list]\n",
        "stacked_results = np.vstack(results)\n",
        "stacked_results.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31925, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwUKbHbFjNXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert preds back into tutor space\n",
        "fixer = relabeler()\n",
        "preds  = stacked_results\n",
        "labels = list(map(fixer.get_best_label, preds))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7yVgyEKkq7I",
        "colab_type": "code",
        "outputId": "77333c39-6eec-42a5-a765-ff4a27d73b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "from collections import Counter\n",
        "correct = 0\n",
        "labelled = zip(train_img_list, labels)\n",
        "classes = Counter() # (pred, actual) : count\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for fn, pred in labelled:\n",
        "  truth = train_labels[fn.split(\"/\")[-1]]\n",
        "  for truelabel in truth:\n",
        "    classes[truelabel] += 1\n",
        "  if pred in truth:\n",
        "    correct += 1\n",
        "    y_true.append(pred)\n",
        "    y_pred.append(pred)\n",
        "  else:\n",
        "    for truelabel in truth: \n",
        "      y_true.append(truelabel)\n",
        "      y_pred.append(pred)\n",
        "    #print(fn, pred, truth)\n",
        "\n",
        "    \n",
        "print(correct, len(train_img_list))\n",
        "print(classes)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-915f891e2d26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlabelled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_img_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (pred, actual) : count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8w3XNrUQaPS",
        "colab_type": "code",
        "outputId": "6f5fb461-ca3b-47f9-b47c-39eeda4ed6d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "#reference https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    #classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(15,15))\n",
        "    \n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_true, y_pred, classes=[x for x in range(-1,20)],\n",
        "                      title='Confusion matrix')\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-46ca2c665a05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Plot non-normalized confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m plot_confusion_matrix(y_true, y_pred, classes=[x for x in range(-1,20)],\n\u001b[0m\u001b[1;32m     70\u001b[0m                       title='Confusion matrix')\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f47URJ3qWn1g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "0a1572ad-6614-4978-c7b8-6198e1548246"
      },
      "source": [
        "## TRANSFER LEARNING\n",
        "# add a single dense relu layer followed by softmax\n",
        "label_pl = tf.placeholder(tf.float32, [None, 20], name='labels')\n",
        "with tf.name_scope(\"train\"):\n",
        "  flat_scores = tf.layers.flatten(sess.graph.get_tensor_by_name(\"SecondStagePostprocessor/convert_scores:0\"))\n",
        "  #first_layer = tf.layers.dense(inputs=flat_scores, units=100*20, name=\"first_layer\", activation=tf.nn.relu)\n",
        "  #second_layer = tf.layers.dense(inputs=first_layer, units=25*20, name=\"second_layer\", activation=tf.nn.relu)\n",
        "  output = tf.layers.dense(inputs=flat_scores, units=20, name=\"output\", activation=tf.nn.relu)\n",
        "\n",
        "\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=output, labels=label_pl))\n",
        "\n",
        "# Train op\n",
        "#with tf.name_scope(\"train\"):\n",
        "# Get gradients of all trainable variables\n",
        "# TODO actually pass vars in, not their names\n",
        "var_list = [v for v in tf.trainable_variables()]\n",
        "gradients = tf.gradients(loss, var_list, unconnected_gradients='none')\n",
        "gradients = list(zip(gradients, var_list))\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Create optimizer and apply gradient descent to the trainable variables\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "train_op = optimizer.apply_gradients(grads_and_vars=gradients)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-12-9a628f538abf>:3: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From <ipython-input-12-9a628f538abf>:6: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIh9B1VKOS_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5bda0f8e-02b1-44cb-e7bd-2bd7e79a8f5b"
      },
      "source": [
        "import time\n",
        "for gradient, var in gradients:\n",
        "    tf.summary.histogram(var.name + '/gradient', gradient)\n",
        "    \n",
        "for var in var_list:\n",
        "    tf.summary.histogram(var.name, var)\n",
        "    \n",
        "tf.summary.scalar('cross_entropy', loss)\n",
        "\n",
        "# Evaluation op: Accuracy of the model\n",
        "with tf.name_scope(\"accuracy\"):\n",
        "    correct_pred = tf.equal(tf.argmax(output, 1), tf.argmax(label_pl, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Merge all summaries together\n",
        "merged_summary = tf.summary.merge_all()\n",
        "\n",
        "# Initialize the FileWriter\n",
        "writer = tf.summary.FileWriter(LOG_DIR + \"/\" + str(time.time()))\n",
        "\n",
        "# Initialize an saver for store model checkpoints\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Summary name output/kernel:0/gradient is illegal; using output/kernel_0/gradient instead.\n",
            "INFO:tensorflow:Summary name output/bias:0/gradient is illegal; using output/bias_0/gradient instead.\n",
            "INFO:tensorflow:Summary name output/kernel:0 is illegal; using output/kernel_0 instead.\n",
            "INFO:tensorflow:Summary name output/bias:0 is illegal; using output/bias_0 instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eyYXJ0O9rfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MHE(labels, max_label=20):\n",
        "  output = np.zeros(max_label, dtype=np.float32)\n",
        "  for lab in labels:\n",
        "    output[lab] = 1.0\n",
        "    \n",
        "  return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJHWakmQ0FEG",
        "colab_type": "code",
        "outputId": "733aecb5-2c5a-4531-b59b-ea3c8e0b51da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from datetime import datetime\n",
        "BATCH_SIZE = 32\n",
        "num_epochs = 10\n",
        "\n",
        "batch_no = 0\n",
        "\n",
        "checkpoint_path = \"/content/drive/My Drive/Colab Notebooks/Models/\"\n",
        "result_list = []\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "train, val = get_training_images(True)\n",
        "# Get the number of training/validation steps per epoch\n",
        "train_batches_per_epoch = int(np.floor(len(train)/BATCH_SIZE))\n",
        "val_batches_per_epoch = int(np.floor(len(val)/ BATCH_SIZE))\n",
        "display_step = 50\n",
        "\n",
        "def load_batch(from_iter):\n",
        "  batch_list = []\n",
        "  labels_list= []\n",
        "  while len(batch_list) < BATCH_SIZE:\n",
        "    nextfile = next(from_iter)\n",
        "    batch_list.append(load_and_preprocess(nextfile))\n",
        "    labels_list.append(MHE(get_label(nextfile)))\n",
        "  return np.stack(batch_list), np.stack(labels_list)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  train_iter  = iter(train) \n",
        "  val_iter = iter(val)\n",
        "  for step in range(train_batches_per_epoch):\n",
        "    stacked_imgs, labels = load_batch(train_iter)\n",
        "    batch_result = sess.run((train_op, loss), feed_dict={\"image_tensor:0\": stacked_imgs, \"labels:0\":labels})\n",
        "    #result_list.append(batch_result)\n",
        "    # Generate summary with the current batch of data and write to file\n",
        "    print(\".\", end=\"\")\n",
        "    if step % display_step == 0:\n",
        "        s = sess.run(merged_summary, feed_dict={\"image_tensor:0\": stacked_imgs, \"labels:0\":labels})\n",
        "\n",
        "        writer.add_summary(s, epoch*train_batches_per_epoch + step)\n",
        "\n",
        "  print(\"{} Start validation\".format(datetime.now()))\n",
        "\n",
        "  test_acc = 0.\n",
        "  test_count = 0\n",
        "  for _ in range(val_batches_per_epoch):\n",
        "      stacked_imgs, labels = load_batch(val_iter)\n",
        "      acc = sess.run(accuracy, feed_dict={\"image_tensor:0\": stacked_imgs, \"labels:0\":labels})\n",
        "      test_acc += acc\n",
        "      test_count += 1\n",
        "  test_acc /= test_count\n",
        "  print(\"{} Validation Accuracy = {:.4f}\".format(datetime.now(),\n",
        "                                                 test_acc))\n",
        "  print(\"{} Saving checkpoint of model...\".format(datetime.now()))\n",
        "\n",
        "  # save checkpoint of the model\n",
        "  checkpoint_name = os.path.join(checkpoint_path,\n",
        "                                 'model_epoch'+str(epoch+1)+'.ckpt')\n",
        "  save_path = saver.save(sess, checkpoint_name)\n",
        "\n",
        "  print(\"{} Model checkpoint saved at {}\".format(datetime.now(),\n",
        "                                                 checkpoint_name))\n",
        "  \n",
        "  \n",
        "#result = sess.run((\"SecondStagePostprocessor/convert_scores:0\", \"detection_classes:0\", \"num_detections:0\"), feed_dict={\"image_tensor:0\": stacked_imgs})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".........."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkDOBfsjrNk0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "8a4a19ae-2f02-4fac-e000-f0e8e8d94b41"
      },
      "source": [
        "sess.graph.get_tensor_by_name(\"train/output:0\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-9c14430bdee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/output:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_tensor_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3652\u001b[0m       raise TypeError(\"Tensor names are strings (or similar), not %s.\" %\n\u001b[1;32m   3653\u001b[0m                       type(name).__name__)\n\u001b[0;32m-> 3654\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3656\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_tensor_by_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3480\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3518\u001b[0m           raise KeyError(\"The name %s refers to a Tensor which does not \"\n\u001b[1;32m   3519\u001b[0m                          \u001b[0;34m\"exist. The operation, %s, does not exist in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3520\u001b[0;31m                          \"graph.\" % (repr(name), repr(op_name)))\n\u001b[0m\u001b[1;32m   3521\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3522\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"The name 'train/output:0' refers to a Tensor which does not exist. The operation, 'train/output', does not exist in the graph.\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZyHcLyndJCf",
        "colab_type": "code",
        "outputId": "38af26f0-e4f4-4214-d2aa-20c1bd1bc7fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'train/output/Relu:0' shape=(?, 20) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNrJljshSMpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fctn15JdKrwp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}