{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/desultir/assign1/blob/master/MNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fQvPcbXfGAnt",
        "colab_type": "code",
        "outputId": "98c14a07-ff27-4fa3-f7c5-6cda53fdf17e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scipy\n",
        "!pip install --upgrade numpy\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: scipy in /usr/local/lib/python3.6/dist-packages (1.2.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.16.2)\n",
            "Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (1.16.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GGkj2RPTaJ9g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as pl\n",
        "from ipywidgets import interact, widgets\n",
        "from matplotlib import animation\n",
        "import h5py\n",
        "from google.colab import drive\n",
        "import time\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kf3k_uTGGlqK",
        "colab_type": "code",
        "outputId": "59e2286e-4e13-4447-fa64-cb21913881cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "with h5py.File('/content/drive/My Drive/Colab Notebooks/Input/train_128.h5','r') as H:\n",
        "  data = np.copy(H['data'])\n",
        "with h5py.File('/content/drive/My Drive/Colab Notebooks/Input/train_label.h5','r') as H:\n",
        "  label = np.copy(H['label'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rJ4v9obPcy13",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import pickle\n",
        "import glob\n",
        "\n",
        "model_dir = \"/content/drive/My Drive/Colab Notebooks/Models/{}.pk\"\n",
        "\n",
        "def list_models():\n",
        "  return glob.glob(model_dir.format(\"*\"))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DOSt_vG94Mfi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# need to normalize input data to avoid overflow/underflow in initial epochs\n",
        "# normalize each feature independently\n",
        "# options are zscore, minmax\n",
        "def preprocess(input_array, method='zscore'):\n",
        "  if method == 'zscore':\n",
        "    for i in range(input_array.shape[1]):\n",
        "      mean = np.mean(input_array[:, i])\n",
        "      std = np.std(input_array[:, i])\n",
        "      input_array[:, i] = (input_array[:, i] - mean) / std\n",
        "  elif method == 'minmax':\n",
        "    for i in range(input_array.shape[1]):\n",
        "      # range 0 to max\n",
        "      input_array[:, i] = (input_array[:, i] - np.min(input_array[:, i]))\n",
        "      # range 0 to 2\n",
        "      input_array[:, i] /= (np.max(input_array[:, i]) / 2)\n",
        "      # range -1 to 1\n",
        "      input_array[:, i] -= 1\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hCFYVtU06MPR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#use stratified sampling to split train into train/validation\n",
        "#this dataset is actually balanced but still good practice\n",
        "def split(dataset, labels, train_percent=.85):\n",
        "  count = len(dataset)\n",
        "  num_classes = np.max(label) + 1\n",
        "  train = []\n",
        "  train_target = []\n",
        "  validate = []\n",
        "  validate_target = []\n",
        "  for i in range(num_classes):\n",
        "    class_data = np.ravel(np.argwhere(label == i))\n",
        "    np.random.shuffle(class_data)\n",
        "    cutoff = int(len(class_data) * train_percent)\n",
        "    train_idx = class_data[:cutoff]\n",
        "    val_idx = class_data[cutoff:]\n",
        "    train.append(dataset[train_idx])\n",
        "    train_target.append(labels[train_idx])\n",
        "    validate.append(dataset[val_idx])\n",
        "    validate_target.append(labels[val_idx])\n",
        "    \n",
        "  return np.vstack(train), np.hstack(train_target), np.vstack(validate), np.hstack(validate_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RsZmOeyySQq9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#need to one-hot encode labels to map to N output nodes (1 per class)\n",
        "#ie convert each label into a (10,) vector where the relevant column is 1\n",
        "\n",
        "def OHE(input_array, num_classes=10):\n",
        "  output = []\n",
        "  for x in input_array:\n",
        "    output.append(np.zeros((10,)))\n",
        "    output[-1][x] = 1\n",
        "  return np.vstack(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q8KpB-EXchIh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## implemented formulae from here: https://towardsdatascience.com/hyper-parameters-in-action-part-ii-weight-initializers-35aee1a28404\n",
        "class InitWeights(object):\n",
        "  def xavier(self, n_in, n_out, uniform=True):\n",
        "    if uniform:\n",
        "      bounds = np.sqrt(6) / (np.sqrt(n_in + n_out))\n",
        "      return self._uniform(n_in, n_out, bounds) \n",
        "    else:\n",
        "      stddev = np.sqrt(2) / (np.sqrt(n_in + n_out))\n",
        "      return self._truncated_normal(n_in, n_out, stddev)\n",
        "    \n",
        "  def he(self, n_in, n_out, uniform=True):\n",
        "    if uniform:\n",
        "      bounds = np.sqrt(2) / (np.sqrt(n_in))\n",
        "      return self._uniform(n_in, n_out, bounds)      \n",
        "    else:\n",
        "      stddev = np.sqrt(6) / (np.sqrt(n_in))\n",
        "      return self._truncated_normal(n_in, n_out, stddev)\n",
        " \n",
        "  def _uniform(self, n_in, n_out, bounds):\n",
        "    W = np.random.uniform(\n",
        "        low=-bounds,\n",
        "        high=bounds,\n",
        "        size=(n_in, n_out)\n",
        "      )\n",
        "    return W\n",
        "  \n",
        "  def _truncated_normal(self, n_in, n_out, stddev):\n",
        "    W = np.random.normal(\n",
        "        loc=0,\n",
        "        scale=stddev,\n",
        "        size=(n_in, n_out)\n",
        "      )\n",
        "    #truncate results - anything > 2 stddev out gets clipped\n",
        "    W[W> 2*stddev] = 2*stddev\n",
        "    W[W<-2*stddev] = -2*stddev\n",
        "    return W\n",
        "  \n",
        "  def __init__(self, init_method=\"xavier\"):\n",
        "    if init_method==\"xavier\":\n",
        "      self.f = self.xavier\n",
        "    elif init_method==\"he\":\n",
        "      self.f = self.he"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "coc2QCMsn63E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calc_MSE(y, y_hat):\n",
        "  error = y-y_hat\n",
        "  return np.mean(np.sum(error**2, axis=1))\n",
        "\n",
        "def labels_from_preds(preds):\n",
        "  return np.argmax(preds, axis=1)\n",
        "\n",
        "def calc_accuracy(labels, target):\n",
        "  return np.sum(labels == target) / len(target)\n",
        "\n",
        "#wasn't sure if we could use a package to shuffle so found this code: https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
        "def shuffle_in_unison(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    shuffled_a = np.empty(a.shape, dtype=a.dtype)\n",
        "    shuffled_b = np.empty(b.shape, dtype=b.dtype)\n",
        "    permutation = np.random.permutation(len(a))\n",
        "    for old_index, new_index in enumerate(permutation):\n",
        "        shuffled_a[new_index] = a[old_index]\n",
        "        shuffled_b[new_index] = b[old_index]\n",
        "    return shuffled_a, shuffled_b\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JbRDaYgyBsh8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The function for ReLU\n",
        "\n",
        "\n",
        "$ f(x) = \\begin{cases}\n",
        "    x & \\mbox{if } x > 0 \\\\\n",
        "    0 & \\mbox{otherwise}\n",
        "\\end{cases}$\n",
        "\n",
        "The function for ReLU's derivative\n",
        "\n",
        "$ f(x) = \\begin{cases}\n",
        "    1 & \\mbox{if } x > 0 \\\\\n",
        "    0 & \\mbox{otherwise}\n",
        "\\end{cases}$\n",
        "\n",
        "\n",
        "The function for Leaky ReLU\n",
        "\n",
        "\n",
        "$ f(x) = \\begin{cases}\n",
        "    x & \\mbox{if } x > 0 \\\\\n",
        "    0.01x & \\mbox{otherwise}\n",
        "\\end{cases}$\n",
        "\n",
        "The function for Leaky ReLU's derivative\n",
        "\n",
        "$ f(x) = \\begin{cases}\n",
        "    1 & \\mbox{if } x > 0 \\\\\n",
        "    0.01 & \\mbox{otherwise}\n",
        "\\end{cases}$\n"
      ]
    },
    {
      "metadata": {
        "id": "kYXDLyEWGG2r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "class Activation(object):\n",
        "    def tanh(self, x):\n",
        "        return np.tanh(x)\n",
        "\n",
        "    def tanh_deriv(self, a):\n",
        "        # a = np.tanh(x)   \n",
        "        return 1.0 - a**2\n",
        "    def logistic(self, x):\n",
        "        return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "    def logistic_deriv(self, a):\n",
        "        # a = logistic(x) \n",
        "        return  a * (1 - a )\n",
        "      \n",
        "    def ReLU(self, x):\n",
        "        x[x<0] =0\n",
        "        return x\n",
        "      \n",
        "    def ReLU_deriv(self, a):\n",
        "        der = np.zeros(a.shape)\n",
        "        der[a>0] =1\n",
        "        return der\n",
        "      \n",
        "    def leaky_ReLU(self, x):\n",
        "        x = np.where(x > 0, x, x*0.01)\n",
        "        return x\n",
        "      \n",
        "    def leaky_ReLU_deriv(self, a):\n",
        "        der = np.full(a.shape, 0.01)\n",
        "        der[a>0] =1\n",
        "        return der\n",
        "      \n",
        "    def softmax(self, x):\n",
        "        # apply max normalization to avoid overflow\n",
        "        if len(x.shape) > 1:\n",
        "          x_norm = (x.T - np.max(x, axis=1)).T\n",
        "          return softmax(x_norm, axis=1)\n",
        "        else:\n",
        "          x_norm = x - np.max(x)\n",
        "          return softmax(x_norm)\n",
        "      \n",
        "    def softmax_deriv(self, a):\n",
        "        return np.ones(a.shape)\n",
        "    \n",
        "    def __init__(self,activation='tanh'):\n",
        "        if activation == 'logistic':\n",
        "            self.f = self.logistic\n",
        "            self.f_deriv = self.logistic_deriv\n",
        "        elif activation == 'tanh':\n",
        "            self.f = self.tanh\n",
        "            self.f_deriv = self.tanh_deriv\n",
        "        elif activation == 'relu':\n",
        "            self.f = self.ReLU\n",
        "            self.f_deriv = self.ReLU_deriv\n",
        "        elif activation == 'leaky_relu':\n",
        "            self.f = self.leaky_ReLU\n",
        "            self.f_deriv = self.leaky_ReLU_deriv\n",
        "        elif activation == 'softmax':\n",
        "            self.f = self.softmax\n",
        "            self.f_deriv = self.softmax_deriv\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HbjWqZ24L3Ot",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Loss_function(object):\n",
        "    def MSE(self, y, y_hat):\n",
        "        error = y-y_hat\n",
        "        loss=np.sum(error**2)\n",
        "        return loss\n",
        "      \n",
        "    def Cross_entropy(self, y, y_hat):\n",
        "        return -np.log(y_hat[np.argmax(y)])\n",
        "      \n",
        "    def l2_reg(self, reg_weight, layers, sample_weight):\n",
        "        accum = 0\n",
        "        for layer in layers:\n",
        "          accum += np.sum(np.square(layer.W))\n",
        "          \n",
        "        return accum*reg_weight*sample_weight/2\n",
        "        \n",
        "    def __init__(self,loss='cross_entropy'):\n",
        "        if loss == 'MSE':\n",
        "            self.loss = self.MSE\n",
        "        elif loss == 'cross_entropy':\n",
        "            self.loss = self.Cross_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BeoakGoCGLvb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class HiddenLayer(object):    \n",
        "    def __init__(self,n_in, n_out,\n",
        "                 activation_last_layer='tanh',activation='tanh', W=None, b=None,\n",
        "                init_uniform=True, weight_decay=None, last_layer=False):\n",
        "        \"\"\"\n",
        "        Typical hidden layer of a MLP: units are fully-connected and have\n",
        "        sigmoidal activation function. Weight matrix W is of shape (n_in,n_out)\n",
        "        and the bias vector b is of shape (n_out,).\n",
        "\n",
        "        NOTE : The nonlinearity used here is tanh\n",
        "\n",
        "        Hidden unit activation is given by: tanh(dot(input,W) + b)\n",
        "\n",
        "        :type n_in: int\n",
        "        :param n_in: dimensionality of input\n",
        "\n",
        "        :type n_out: int\n",
        "        :param n_out: number of hidden units\n",
        "\n",
        "        :type activation: string\n",
        "        :param activation: Non linearity to be applied in the hidden\n",
        "                           layer\n",
        "        :type init_uniform: bool\n",
        "        :param init_uniform: Whether to draw init weights from uniform dist (else normal)\n",
        "        \n",
        "        :type weight_decay: float/None/False\n",
        "        :param weight_decay: Weight to apply to l2 reg loss factor (else none/false)\n",
        "        \"\"\"\n",
        "        self.input=None\n",
        "        self.dropout_cache=None\n",
        "        self.activation=Activation(activation).f\n",
        "        self.last_layer=last_layer\n",
        "        \n",
        "        if activation=='relu':\n",
        "          self.init_weights = InitWeights(\"he\").f\n",
        "        else:\n",
        "          self.init_weights = InitWeights(\"xavier\").f\n",
        "        \n",
        "        # activation deriv of last layer\n",
        "        self.activation_deriv=None\n",
        "        if activation_last_layer:\n",
        "            self.activation_deriv=Activation(activation_last_layer).f_deriv\n",
        "\n",
        "        if W is not None:\n",
        "          self.W = W\n",
        "        else:\n",
        "          self.W = self.init_weights(n_in, n_out, init_uniform)\n",
        "\n",
        "        if b is not None:\n",
        "          self.b = b\n",
        "        else:\n",
        "          self.b = np.zeros(n_out,)  \n",
        "          \n",
        "        self.weight_decay = weight_decay\n",
        "          \n",
        "        self.grad_W = np.zeros(self.W.shape)\n",
        "        self.grad_b = np.zeros(self.b.shape)\n",
        "        \n",
        "        # create arrays to store the velocity values for momentum calculation\n",
        "        self.vW = np.zeros(self.W.shape)\n",
        "        self.vb = np.zeros(self.b.shape)\n",
        "    \n",
        "    def dropout(self, nodes, probability):\n",
        "        #This distribution decides what nodes will be on or not. We then rescale the on nodes proportionally to the probability that it is off.\n",
        "        \n",
        "        active_nodes = np.random.binomial(1, probability, size=nodes.shape) / probability\n",
        "        output = np.multiply(nodes, active_nodes)\n",
        "        return output, active_nodes\n",
        "    \n",
        "    def forward(self, input, probability):\n",
        "        '''\n",
        "        :type input: numpy.array\n",
        "        :param input: a symbolic tensor of shape (n_in,)\n",
        "        '''\n",
        "        lin_output = np.dot(input, self.W) + self.b\n",
        "        self.output = (\n",
        "            lin_output if self.activation is None\n",
        "            else self.activation(lin_output)\n",
        "        )\n",
        "        self.input=input\n",
        "        \n",
        "        if self.last_layer:\n",
        "            probability=1\n",
        "        \n",
        "        self.output, self.dropout_cache = self.dropout(self.output, probability)\n",
        "        return self.output\n",
        "    \n",
        "    def backward(self, delta, output_layer=False, sampleweight=1):\n",
        "        delta *= self.dropout_cache\n",
        "        self.grad_W = np.atleast_2d(self.input).T.dot(np.atleast_2d(delta))\n",
        "        \n",
        "        if self.weight_decay:\n",
        "            self.grad_W += self.W * self.weight_decay * sampleweight\n",
        "        self.grad_b = np.sum(delta, axis=0)\n",
        "        if self.activation_deriv:\n",
        "            delta = delta.dot(self.W.T) * self.activation_deriv(self.input)\n",
        "        return delta\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_LKgiGhdGQbS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class MLP:\n",
        "    \"\"\"\n",
        "    \"\"\"      \n",
        "    def __init__(self, layers=None, activation=[None,'tanh','tanh'], init_uniform=True, weight_decay=False, from_file=None):\n",
        "        \"\"\"\n",
        "        :param layers: A list containing the number of units in each layer.\n",
        "        Should be at least two values\n",
        "        :param activation: The activation function to be used. Can be\n",
        "        \"logistic\" or \"tanh\"\n",
        "        :param init_uniform: Whether to draw init weights from uniform dist (else normal)\n",
        "        :param weight_decay: lambda for strength of l2 regularization on weights (else False/None for no reg)\n",
        "        :param from_file: a file to load to get pretrained weights. \n",
        "        \"\"\"        \n",
        "        ### initialize layers\n",
        "        self.layers=[]\n",
        "        self.params= {'activation':activation, 'layers':layers, 'weight_decay': weight_decay, 'init_uniform': init_uniform}\n",
        "        \n",
        "        self.es_epochs=None\n",
        "        if from_file:\n",
        "          dumped_model = self._load_model(from_file)\n",
        "          self.params = dumped_model['params']\n",
        "          self.activation=self.params['activation']\n",
        "          layers = self.params['layers']\n",
        "          init_uniform = self.params['init_uniform']\n",
        "          for i in range(len(self.params['layers'])-1):\n",
        "              if i==len(self.params['layers'])-2:\n",
        "                self.layers.append(HiddenLayer(layers[i],layers[i+1],activation[i],activation[i+1],  \n",
        "                                              W=dumped_model['weights'][i][0], b=dumped_model['weights'][i][1], weight_decay=weight_decay, init_uniform=init_uniform,last_layer=True))\n",
        "              else:\n",
        "                self.layers.append(HiddenLayer(layers[i],layers[i+1],activation[i],activation[i+1],  \n",
        "                                              W=dumped_model['weights'][i][0], b=dumped_model['weights'][i][1], weight_decay=weight_decay, init_uniform=init_uniform))\n",
        "        else:\n",
        "          self.activation=activation\n",
        "          for i in range(len(layers)-1):\n",
        "              if i==len(layers)-2:\n",
        "                self.layers.append(HiddenLayer(layers[i],layers[i+1],activation[i],activation[i+1], weight_decay=weight_decay, init_uniform=init_uniform,last_layer=True))\n",
        "              else:\n",
        "                self.layers.append(HiddenLayer(layers[i],layers[i+1],activation[i],activation[i+1], weight_decay=weight_decay, init_uniform=init_uniform))\n",
        "    \n",
        "    def forward(self,input, dropout_p=1):\n",
        "        for layer in self.layers:\n",
        "            output=layer.forward(input, dropout_p)\n",
        "            input=output\n",
        "        return output\n",
        "      \n",
        "    def set_early_stopping(self, validation, validation_labels, num_epochs=10):\n",
        "        # for early stopping\n",
        "        self.validation = validation\n",
        "        self.validation_labels = labels_from_preds(validation_labels)\n",
        "        self.es_epochs = num_epochs\n",
        "      \n",
        "    def calculate_loss(self,y,y_hat):\n",
        "        activation_deriv=Activation(self.activation[-1]).f_deriv\n",
        "        # call to loss function\n",
        "        loss=[]\n",
        "        delta=[]\n",
        "\n",
        "        for i, single_y in enumerate(y):\n",
        "          loss.append(Loss_function('MSE').loss(single_y, y_hat[i]))\n",
        "          error = single_y-y_hat[i]\n",
        "        # calculate the delta of the output layer\n",
        "          delta.append(np.array(-error*activation_deriv(y_hat[i])))\n",
        "        # return loss and delta\n",
        "        loss = np.array(loss)\n",
        "        if self.params['weight_decay']:\n",
        "          loss += Loss_function().l2_reg(self.params['weight_decay'], self.layers, len(y)/self.Xcount)\n",
        "\n",
        "        return loss,np.array(delta)\n",
        "        \n",
        "    def backward(self,delta, sampleweight):\n",
        "        delta=self.layers[-1].backward(delta,output_layer=True, sampleweight=sampleweight)\n",
        "        for layer in reversed(self.layers[:-1]):\n",
        "            delta=layer.backward(delta, sampleweight=sampleweight)\n",
        "            \n",
        "    def update(self,lr):\n",
        "        for layer in self.layers:\n",
        "            layer.W -= lr * layer.grad_W\n",
        "            layer.b -= lr * layer.grad_b\n",
        "            \n",
        "    def update_momentum(self, lr, mom):\n",
        "        for layer in self.layers:\n",
        "            layer.vW = mom * layer.vW + lr * layer.grad_W\n",
        "            layer.vb = mom * layer.vb + lr * layer.grad_b\n",
        "            layer.W -= layer.vW\n",
        "            layer.b -= layer.vb        \n",
        "\n",
        "    def fit(self,X,y,learning_rate=0.1, epochs=100, dropout_p=1):\n",
        "        \"\"\"\n",
        "        Online learning.\n",
        "        :param X: Input data or features\n",
        "        :param y: Input targets\n",
        "        :param learning_rate: parameters defining the speed of learning\n",
        "        :param epochs: number of times the dataset is presented to the network for learning\n",
        "        \"\"\" \n",
        "        X=np.array(X)\n",
        "        y=np.array(y)\n",
        "        to_return = np.zeros(epochs)\n",
        "        self.Xcount = len(X)\n",
        "        if self.es_epochs:\n",
        "            validation_acc = np.zeros(epochs)\n",
        "        for k in range(epochs):\n",
        "            #print('epoch', k)\n",
        "            loss=np.zeros(X.shape[0])\n",
        "            for it in range(X.shape[0]):\n",
        "                i=np.random.randint(X.shape[0])\n",
        "                \n",
        "                # forward pass\n",
        "                y_hat = self.forward(X[i], dropout_p)\n",
        "                # backward pass\n",
        "                loss[it],delta=self.calculate_loss([y[i]],[y_hat])\n",
        "                self.backward(delta, 1/self.Xcount)\n",
        "                # update\n",
        "                self.update(learning_rate)\n",
        "            to_return[k] = np.mean(loss)\n",
        "            if not k % 10:\n",
        "              print(\".\", end=\"\")\n",
        "            if self.es_epochs:\n",
        "              preds = self.predict(self.validation)\n",
        "              validation_acc[k] = calc_accuracy(labels_from_preds(preds), self.validation_labels)\n",
        "              if k - np.argmax(validation_acc) > self.es_epochs:\n",
        "                print(\"Haven't improved accuracy on validation set in {} epochs, stopping\".format(self.es_epochs))\n",
        "                break\n",
        "        return to_return\n",
        "      \n",
        "    def fit_mb(self,X,y,mini_batch_size,learning_rate=0.1, epochs=100, dropout_p=1):\n",
        "        \"\"\"\n",
        "        Online learning.\n",
        "        :param X: Input data or features\n",
        "        :param y: Input targets\n",
        "        :param learning_rate: parameters defining the speed of learning\n",
        "        :param epochs: number of times the dataset is presented to the network for learning\n",
        "        :param early_stop: int: stop if haven't improved in this many epochs\n",
        "        \"\"\" \n",
        "        X=np.array(X)\n",
        "        y=np.array(y)\n",
        "        to_return = np.zeros(epochs) #array to store values of mean loss for each epoch for plotting later\n",
        "        if self.es_epochs:\n",
        "            validation_acc = np.zeros(epochs)\n",
        "        self.Xcount = len(X)\n",
        "        \n",
        "        for k in range(epochs): #for each epoch\n",
        "            X, y = shuffle_in_unison(X, y) #shuffle the input data and input targets\n",
        "            loss=np.zeros(X.shape[0]) #create array of zeros whose lengths = #samples.\n",
        "            \n",
        "            #partition training data (X, y) into mini-batches\n",
        "            for j in range(0, X.shape[0], mini_batch_size):\n",
        "              X_mini = X[j:j + mini_batch_size]\n",
        "              y_mini = y[j:j + mini_batch_size]\n",
        "              # forward pass\n",
        "              y_hat = self.forward(X_mini, dropout_p) #forward feed the mini_batches to get outputs (y_hat)\n",
        "              \n",
        "              # backwards pass\n",
        "              loss[j:j + mini_batch_size], delta=self.calculate_loss(y[j:j + mini_batch_size], y_hat) #input y and y_hat into calculate_loss. Output = loss and delta\n",
        "              self.backward(delta, mini_batch_size/self.Xcount) #pass delta from calculate_loss to backward.\n",
        "\n",
        "              # update\n",
        "              self.update(learning_rate)\n",
        "            to_return[k] = np.mean(loss) #add mean loss to to_return\n",
        "            if not k % 10:\n",
        "              print(\".\", end=\"\")\n",
        "            if self.es_epochs:\n",
        "              preds = self.predict(self.validation)\n",
        "              validation_acc[k] = calc_accuracy(labels_from_preds(preds), self.validation_labels)\n",
        "              if k - np.argmax(validation_acc) > self.es_epochs:\n",
        "                print(\"Haven't improved accuracy on validation set in {} epochs, stopping\".format(self.es_epochs))\n",
        "                break\n",
        "              \n",
        "        return to_return[:k]\n",
        "      \n",
        "    def fit_SGD_momentum(self,X,y,learning_rate=0.1, epochs=100, momentum=0.9, dropout_p=1):\n",
        "        \"\"\"\n",
        "        Online learning.\n",
        "        :param X: Input data or features\n",
        "        :param y: Input targets\n",
        "        :param learning_rate: parameters defining the speed of learning\n",
        "        :param epochs: number of times the dataset is presented to the network for learning\n",
        "        \"\"\" \n",
        "        X=np.array(X)\n",
        "        y=np.array(y)\n",
        "        to_return = np.zeros(epochs)\n",
        "        self.Xcount = len(X)\n",
        "        if self.es_epochs:\n",
        "            validation_acc = np.zeros(epochs)\n",
        "        for k in range(epochs):\n",
        "            loss=np.zeros(X.shape[0])\n",
        "            \n",
        "            # loop through training examples\n",
        "            for j in range(X.shape[0]):\n",
        "              i=np.random.randint(X.shape[0])\n",
        "                \n",
        "              # forward pass\n",
        "              y_hat = self.forward(X[i], dropout_p)\n",
        "                \n",
        "              # backward pass\n",
        "              loss[j],delta=self.calculate_loss([y[i]],[y_hat])\n",
        "              self.backward(delta, X.shape[0]/self.Xcount)\n",
        "                \n",
        "              # update\n",
        "              self.update_momentum(learning_rate, momentum)\n",
        "            to_return[k] = np.mean(loss)\n",
        "            if not k % 10:\n",
        "              print(\".\", end=\"\")\n",
        "            if self.es_epochs:\n",
        "              preds = self.predict(self.validation)\n",
        "              validation_acc[k] = calc_accuracy(labels_from_preds(preds), self.validation_labels)\n",
        "              if k - np.argmax(validation_acc) > self.es_epochs:\n",
        "                print(\"Haven't improved accuracy on validation set in {} epochs, stopping\".format(self.es_epochs))\n",
        "                break\n",
        "        return to_return  \n",
        "\n",
        "    def predict(self, x):\n",
        "        x = np.array(x)\n",
        "        output = []\n",
        "        for i in np.arange(x.shape[0]):\n",
        "            output.append(self.forward(x[i,:]))\n",
        "        return np.vstack(output)\n",
        "      \n",
        "\n",
        "    def save_model(self, name):\n",
        "      model = {'params':self.params, 'weights':[]}\n",
        "      for x in self.layers:\n",
        "        model['weights'].append((x.W, x.b))\n",
        "        \n",
        "      with open(model_dir.format(name), 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "        \n",
        "    def _load_model(self, name):\n",
        "      with open(model_dir.format(name), 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DOPAt_9nGd5y",
        "colab_type": "code",
        "outputId": "e33e6d37-53a6-448e-bdee-0ea38575a5e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "np.seterr(all=\"warn\")\n",
        "np.random.seed(1)\n",
        "procdata = np.copy(data)\n",
        "preprocess(procdata, 'zscore')\n",
        "\n",
        "#split data\n",
        "train, train_target, validate, validate_target = split(procdata, label)\n",
        "#one hot encode targets\n",
        "train_target = OHE(train_target, 10)\n",
        "validate_target = OHE(validate_target, 10)\n",
        "second_layer = False\n",
        "relu = True\n",
        "if second_layer:\n",
        "  nn = MLP([128,60,30,10], [None,'logistic','logistic','tanh'])\n",
        "elif relu:\n",
        "  nn = MLP([128,60,10, 10], [None, 'relu','relu', 'softmax'])\n",
        "  #nn.set_early_stopping(validate, validate_target, 10)\n",
        "  start = time.time()\n",
        "  MSE = nn.fit_mb(train, train_target, learning_rate=0.001, epochs=20, mini_batch_size=32)\n",
        "  print(\"{}s to train\".format(time.time() - start))\n",
        "else:\n",
        "  nn = MLP([128,60,10], [None,'logistic','tanh'], init_uniform=False, weight_decay=0.5)\n",
        "  start = time.time()\n",
        "  MSE = nn.fit_mb(train, train_target, learning_rate=0.01, epochs=500, mini_batch_size=32)\n",
        "  print(\"{}s to train\".format(time.time() - start))\n",
        "print('loss:%f'%MSE[-1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "..36.93035411834717s to train\n",
            "loss:0.112724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-U-Uf7i9YX9t",
        "colab_type": "code",
        "outputId": "2b323197-616d-4f6d-e96c-5f2331a39f06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "pl.figure(figsize=(15,4))\n",
        "pl.plot(MSE)\n",
        "pl.grid()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAAD8CAYAAAA/m+aTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wd5TkiOJ0UQJAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "oAAnBZZ97anF",
        "colab_type": "code",
        "outputId": "c7a4a822-2f15-4cf1-c3ab-275f22642dff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8532222222222222"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "ms28tiW02uzz",
        "colab_type": "code",
        "outputId": "a85ce6f2-021a-4ab3-dfc0-85cda930b856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#get validation score\n",
        "#nn = load_model(\"tdm1\")\n",
        "preds = nn.predict(validate)\n",
        "\n",
        "loss = calc_MSE(preds, validate_target)\n",
        "loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: underflow encountered in square\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2558237762683418"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "Chank-E-im1p",
        "colab_type": "code",
        "outputId": "3fe1dcf8-b56f-45b5-ea92-7affcc4b2a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "nn.save_model(\"relu.1\")\n",
        "\n",
        "calc_accuracy(labels_from_preds(preds), labels_from_preds(validate_target)) # we have to de-OHE the predictions and the target data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.856"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "VPIf-BuaBzlC",
        "colab_type": "code",
        "outputId": "98a8f038-23c9-49ed-f484-39ca773a86b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.mean(procdata)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.4332387956368016e-19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "metadata": {
        "id": "CauivsamljjX",
        "colab_type": "code",
        "outputId": "bfd425c0-0f66-45c2-d7bc-a4ea1d063d33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        }
      },
      "cell_type": "code",
      "source": [
        "np.seterr(all=\"warn\")\n",
        "np.random.seed(1)\n",
        "procdata = np.copy(data)\n",
        "preprocess(procdata, 'zscore')\n",
        "\n",
        "#split data\n",
        "train, train_target, validate, validate_target = split(data, label)\n",
        "#one hot encode targets\n",
        "train_target = OHE(train_target, 10)\n",
        "validate_target = OHE(validate_target, 10)\n",
        "second_layer = False\n",
        "relu = False\n",
        "if second_layer:\n",
        "  nn = MLP([128,60,30,10], [None,'logistic','logistic','tanh'])\n",
        "elif relu:\n",
        "  nn = MLP([128,60,10], [None, 'relu', 'relu'], False)\n",
        "  start = time.time()\n",
        "  MSE = nn.fit_SGD_momentum(train, train_target, learning_rate=0.001, epochs=25)\n",
        "  print(\"{}s to train\".format(time.time() - start))\n",
        "else:\n",
        "  nn = MLP([128,60,10], [None,'logistic','tanh'], False)\n",
        "  start = time.time()\n",
        "  MSE = nn.fit_SGD_momentum(train, train_target, learning_rate=0.01, epochs=25)\n",
        "  print(\"{}s to train\".format(time.time() - start))\n",
        "print('loss:%f'%MSE[-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: overflow encountered in exp\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: underflow encountered in exp\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: RuntimeWarning: underflow encountered in multiply\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:73: RuntimeWarning: underflow encountered in multiply\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:74: RuntimeWarning: underflow encountered in multiply\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: underflow encountered in true_divide\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "."
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-0fd8b67be865>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'logistic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tanh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0mMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_SGD_momentum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}s to train\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss:%f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mMSE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-0345c42cdc37>\u001b[0m in \u001b[0;36mfit_SGD_momentum\u001b[0;34m(self, X, y, learning_rate, epochs, momentum, dropout_p)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m               \u001b[0;31m# update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_momentum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mto_return\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-0345c42cdc37>\u001b[0m in \u001b[0;36mupdate_momentum\u001b[0;34m(self, lr, mom)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_momentum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmom\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvW\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmom\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "XAmMCUzSupSo",
        "colab_type": "code",
        "outputId": "dc504048-9388-4cd2-904a-e54dc3b7f1bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "cell_type": "code",
      "source": [
        "pl.figure(figsize=(15,4))\n",
        "pl.plot(MSE)\n",
        "pl.grid()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2gAAAD4CAYAAACZmMXjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "HExGAmdDalm0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Introduction\n",
        "The experiment task consisted of building a neural network to perform multi-class classification on a supplied dataset without the use of Deep Learning frameworks (e.g. TensorFlow, Caffe, and KERAS). The dataset consisted of 60,000 labeled training samples and 10,000 unlabeled test samples. The structure of the data (e.g. image, video, etc) was unknown. The performance of the neural network was evaluated in terms of the accuracy metric. Various neural network structures and parameters were trailed to maximise speed and accuracy.\n",
        "\n",
        "The objective of building the neural network without Deep Learning frameworks was to gain a comprehensive understanding of the math and mechanics behind neural networks.\n",
        "\n",
        "\n",
        "\n",
        "##SGD with Momentum\n",
        "Momentum ($v_t$) is an exponentially weighted average of a neural networks gradients. It is used to update the weights ($w_t$) and baises ($b_t$) of a network.\n",
        "\n",
        "$$v_t = \\beta v_{t-1} + \\eta \\nabla_w J(w)$$\n",
        "$$w_t = w_{t-1} - v_t$$\n",
        "\n",
        "Momentum increases for features whose gradients point in the same direction and reduces for features whose gradients change direction. By reducing the fluctuation of gradients convergence is generally sped up. The hyper-parameter $\\beta$ takes a value between 0 - 1 and dictates how many samples are included in the exponential weighted average. A small $\\beta$ value will increase fluctuation because the average is taken over a smaller number of examples. A large $\\beta$ will increase smoothing because the average is taken over a larger number of examples. A $\\beta$ value of 0.9 provides a balance between the two extremes.\n",
        "\n",
        "##Gradient Descent\n",
        "Gradient descent is a machine learning optimization method. In deep learning it is used to calculate the model parameters (weights and biases) that minimise the cost function. The gradient descent method invovles iterating through a training dataset and updating weights and baises in accordance with the gradient of error. There are three types of gradient descent. Each uses a different number of training examples to update the model parameters:\n",
        "*   **Batch Gradient Descent** uses the entire training dataset to calculate gradients and update the parameters. Because the entire training dataset is considered parameters updates are smooth however, it can take a long time to make a single update.\n",
        "*   **Stochastic Gradient Descent (SGD)** uses a single randomly selected sample from the training dataset to calculate gradients and update the parameters. Parameter updates are fast but very noisey.\n",
        "*   **Mini-batch Gradient Descent** uses a subset of the training data (e.g. batches of 1000 samples) to calculate gradients and update the parameters. Mini-batch gradient descent is a compromise between batch and stochastic gradient descent. The mini-batch size can be adjusted to find the appropriate balance between fast convergence and noisey updates. "
      ]
    },
    {
      "metadata": {
        "id": "BRDGNA5IPpGY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Louis testing stuff below"
      ]
    },
    {
      "metadata": {
        "id": "WLXWBGImOPVM",
        "colab_type": "code",
        "outputId": "184bf1f3-441d-439b-947e-c04b0df037f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "np.seterr(all=\"warn\")\n",
        "np.random.seed(1)\n",
        "procdata = np.copy(data)\n",
        "preprocess(procdata, 'zscore')\n",
        "\n",
        "#split data\n",
        "train, train_target, validate, validate_target = split(procdata, label)\n",
        "#one hot encode targets\n",
        "train_target = OHE(train_target, 10)\n",
        "validate_target = OHE(validate_target, 10)\n",
        "second_layer = False\n",
        "relu = True\n",
        "if second_layer:\n",
        "  nn = MLP([128,60,30,10], [None,'logistic','logistic','tanh'])\n",
        "elif relu:\n",
        "  nn = MLP([128,80,60, 30,10], [None, 'relu','relu','relu', 'softmax'])\n",
        "  start = time.time()\n",
        "  MSE = nn.fit_mb(train, train_target, learning_rate=0.001,mini_batch_size=32, epochs=500, dropout_p=0.5)\n",
        "  print(\"{}s to train\".format(time.time() - start))\n",
        "else:\n",
        "  nn = MLP([128,60,10], [None,'logistic','tanh'], init_uniform=False, weight_decay=0.5)\n",
        "  start = time.time()\n",
        "  MSE = nn.fit_mb(train, train_target, learning_rate=0.01, epochs=500, mini_batch_size=32)\n",
        "  print(\"{}s to train\".format(time.time() - start))\n",
        "print('loss:%f'%MSE[-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: underflow encountered in square\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/special/_logsumexp.py:112: RuntimeWarning: underflow encountered in exp\n",
            "  tmp = np.exp(a - a_max)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/special/_logsumexp.py:215: RuntimeWarning: underflow encountered in exp\n",
            "  return np.exp(x - logsumexp(x, axis=axis, keepdims=True))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "............"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:71: RuntimeWarning: underflow encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "......................."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: RuntimeWarning: underflow encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "............1733.7815234661102s to train\n",
            "loss:0.228955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0C-vQveSFXUZ",
        "colab_type": "code",
        "outputId": "4306b888-bd7d-4ac9-a6d9-015b22784427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "preds = nn.predict(validate)\n",
        "calc_accuracy(labels_from_preds(preds), labels_from_preds(validate_target))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8802222222222222"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "6yXjnNSj_bv3",
        "colab_type": "code",
        "outputId": "f7246b70-7133-40c8-d952-84754603e524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "pl.figure(figsize=(15,4))\n",
        "pl.plot(MSE)\n",
        "pl.grid()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAD8CAYAAADkIEyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4m+d9//v3DYAAOMBNglMitZct\nWZYleVO248iOY6VZP2c0STPcnKtO0nXapL9eaev+enI1OZmn7nCbxGnTxHGTOFUTxdv0HpIsWZsa\n1CLFPcGBfZ8/ANIUTVmUTQgg9Xldly7xefCQ/Ar82sQH93iMtRYRERERERHJTI50FyAiIiIiIiLn\nptAmIiIiIiKSwRTaREREREREMphCm4iIiIiISAZTaBMREREREclgCm0iIiIiIiIZTKFNREREREQk\ngym0iYiIiIiIZDCFNhERERERkQzmStc3Li0ttXV1den69uc0PDxMbm5uusuQOUw9Jqmk/pJUU49J\nKqm/JNUyrcd27tzZba0tO991aQttdXV17NixI13f/pwaGxtpaGhIdxkyh6nHJJXUX5Jq6jFJJfWX\npFqm9Zgx5uR0rtP0SBERERERkQym0CYiIiIiIpLBFNpEREREREQymEKbiIiIiIhIBlNoExERERER\nyWAKbSIiIiIiIhlsWqHNGLPZGNNkjDlqjPnyFI/PM8Y8bYzZZYzZY4y5feZLFRERERERufScN7QZ\nY5zAfcBtwArgI8aYFZMu+0vgIWvtFcBdwD/OdKEXw2/3tvHI8Ui6yxARERERERk3nZG29cBRa22z\ntTYMPAhsmXSNBfKTHxcAZ2auxIvn8YMdPH5SoU1ERERERDKHaxrXVAOnJxy3ABsmXfPXwGPGmC8A\nucAtM1LdReZyGGy6ixAREREREZlgOqFtOj4CPGCt/aYx5mrgP4wxq6y18YkXGWPuBu4G8Pv9NDY2\nztC3nxmd7SGisXjG1SVzy9DQkHpMUkb9JammHpNUUn9Jqs3WHptOaGsFaicc1yTPTfQZYDOAtfYl\nY4wXKAU6J15krb0fuB9g3bp1tqGh4e1VnSJP9u9jZ8dJMq0umVsaGxvVY5Iy6i9JNfWYpJL6S1Jt\ntvbYdNa0bQcWG2PqjTFuEhuNbJ10zSngZgBjzHLAC3TNZKEXg9NhiGl+pIiIiIiIZJDzhjZrbRS4\nB3gUOEhil8j9xph7jTF3Ji/7E+BzxpjXgZ8Cn7LWzrr443IY4rOuahERERERmcumtabNWrsN2Dbp\n3FcnfHwAuHZmS7v4nE6NtImIiIiISGaZ1s21LxUaaRMRERERkUyj0DaB0+EgZmEWzuwUEREREZE5\nSqFtApfDAGi0TUREREREMoZC2wTOZGiLxuPnuVJEREREROTiUGibYCy0xTTUJiIiIiIiGUKhbQKX\nQpuIiIiIiGQYhbYJNNImIiIiIiKZRqFtAtf4mjaFNhERERERyQwKbRM4HYmnQyNtIiIiIiKSKRTa\nJtBIm4iIiIiIZBqFtgnG17TFFNpERERERCQzKLRN4HLqPm0iIiIiIpJZFNom0O6RIiIiIiKSaRTa\nJtCaNhERERERyTQKbRM4jEbaREREREQksyi0TfDGmjaFNhERERERyQwKbRPoPm0iIiIiIpJpFNom\ncGkjEhERERERyTAKbRM4HdryX0REREREMotC2wQaaRMRERERkUyj0DaBU1v+i4iIiIhIhlFom8A1\nthFJTKFNREREREQyg0LbBBppExERERGRTKPQNsHYfdq0pk1ERERERDKFQtsE2j1SREREREQyjULb\nBE6jkTYREREREcks0wptxpjNxpgmY8xRY8yXp3j828aY3ck/h40x/TNfauppTZuIiIiIiGQa1/ku\nMMY4gfuAdwEtwHZjzFZr7YGxa6y1fzTh+i8AV6Sg1pTTmjYREREREck00xlpWw8ctdY2W2vDwIPA\nlre4/iPAT2eiuIvNqZtri4iIiIhIhjnvSBtQDZyecNwCbJjqQmPMfKAeeOocj98N3A3g9/tpbGy8\nkFpTLhBOhLVDTYdpDB5PczUyVw0NDWVc78vcof6SVFOPSSqpvyTVZmuPTSe0XYi7gJ9ba2NTPWit\nvR+4H2DdunW2oaFhhr/9OzMwGoGnHqN+4SIarqtPdzkyRzU2NpJpvS9zh/pLUk09Jqmk/pJUm609\nNp3pka1A7YTjmuS5qdzFLJ0aCeAanx6pLf9FRERERCQzTCe0bQcWG2PqjTFuEsFs6+SLjDHLgCLg\npZkt8eLR7pEiIiIiIpJpzhvarLVR4B7gUeAg8JC1dr8x5l5jzJ0TLr0LeNBaO2sTz/hIW2zW/hNE\nRERERGSOmdaaNmvtNmDbpHNfnXT81zNXVnpopE1ERERERDLNtG6ufakwxuAw2vJfREREREQyh0Lb\nJA6jkTYREREREckcCm2TJEbatHukiIiIiIhkBoW2SZwaaRMRERERkQyi0DaJw0BcoU1ERERERDKE\nQtskGmkTEREREZFMotA2icMY7R4pIiIiIiIZQ6FtEo20iYiIiIhIJlFom0T3aRMRERERkUyi0DaJ\nRtpERERERCSTKLRN4nDoPm0iIiIiIpI5FNomcRpDNKaRNhERERERyQwKbZNoTZuIiIiIiGQShbZJ\nHFrTJiIiIiIiGUShbRKnRtpERERERCSDKLRNoumRIiIiIiKSSRTaJtFIm4iIiIiIZBKFtkkSa9q0\n5b+IiIiIiGQGhbZJnMZopE1ERERERDKGQtsk2j1SREREREQyiULbJE6H1rSJiIiIiEjmUGibRCNt\nIiIiIiKSSRTaJtHukSIiIiIikkkU2iZxGKPdI0VEREREJGMotE3iMBCLaaRNREREREQyw7RCmzFm\nszGmyRhz1Bjz5XNc82FjzAFjzH5jzE9mtsyLR2vaREREREQkk7jOd4ExxgncB7wLaAG2G2O2WmsP\nTLhmMfAV4FprbZ8xpjxVBaea1rSJiIiIiEgmmc5I23rgqLW22VobBh4Etky65nPAfdbaPgBrbefM\nlnnxOAzErEKbiIiIiIhkhvOOtAHVwOkJxy3AhknXLAEwxrwAOIG/ttY+MvkLGWPuBu4G8Pv9NDY2\nvo2SUysejRAKm4ysTeaGoaEh9ZekjPpLUk09Jqmk/pJUm609Np3QNt2vsxhoAGqAZ40xl1lr+yde\nZK29H7gfYN26dbahoWGGvv3MefDQY2DiZGJtMjc0NjaqvyRl1F+SauoxSSX1l6TabO2x6UyPbAVq\nJxzXJM9N1AJstdZGrLXHgcMkQtysozVtIiIiIiKSSaYT2rYDi40x9cYYN3AXsHXSNb8iMcqGMaaU\nxHTJ5hms86JxONB92kREREREJGOcN7RZa6PAPcCjwEHgIWvtfmPMvcaYO5OXPQr0GGMOAE8D/7e1\ntidVRaeS00DcQlyjbSIiIiIikgGmtabNWrsN2Dbp3FcnfGyBP07+mdUcJvF3zFocmPQWIyIiIiIi\nl7xp3Vz7UuIcC20aaRMRERERkQyg0DaJwyRSW1ShTUREREREMoBC2yTj0yNjCm0iIiIiIpJ+Cm2T\njE2P1A6SIiIiIiKSCRTaJpm4EYmIiIiIiEi6KbRNoo1IREREREQkkyi0TTI20hbVmjYREREREckA\nCm2TOJOpTSNtIiIiIiKSCRTaJhkfaVNoExERERGRDKDQNonWtImIiIiISCZRaJvEoS3/RUREREQk\ngyi0TaKRNhERERERySQKbZNoTZuIiIiIiGQShbZJHEa7R4qIiIiISOZQaJvEqfu0iYiIiIhIBlFo\nm2RsemTcKrSJiIiIiEj6KbRN4tSaNhERERERySAKbZM4ks9ITFv+i4iIiIhIBlBom0Rr2kRERERE\nJJMotE2i3SNFRERERCSTKLRNojVtIiIiIiKSSRTaJhnbPVIjbSIiIiIikgkU2ibRSJuIiIiIiGQS\nhbZJHOMbkWj3SBERERERST+FtkmykqktrNAmIiIiIiIZYFqhzRiz2RjTZIw5aoz58hSPf8oY02WM\n2Z3889mZL/XicDsTf4+GY+ktREREREREBHCd7wJjjBO4D3gX0AJsN8ZstdYemHTpz6y196Sgxotq\nLLSNKLSJiIiIiEgGmM5I23rgqLW22VobBh4EtqS2rPRxGIPH5SAYUWgTEREREZH0m05oqwZOTzhu\nSZ6b7APGmD3GmJ8bY2pnpLo0yXE7NdImIiIiIiIZ4bzTI6fpf4CfWmtDxpjfB34E3DT5ImPM3cDd\nAH6/n8bGxhn69jNnaGgIR9xB86lWGhu7012OzEFDQ0MZ2fsyN6i/JNXUY5JK6i9JtdnaY9MJba3A\nxJGzmuS5cdbangmH/wZ8faovZK29H7gfYN26dbahoeFCar0oGhsbKfRBYUk+DQ1r012OzEGNjY1k\nYu/L3KD+klRTj0kqqb8k1WZrj01neuR2YLExpt4Y4wbuArZOvMAYUznh8E7g4MyVePHluF2MhKPp\nLkNEREREROT8I23W2qgx5h7gUcAJ/MBau98Ycy+ww1q7FfiiMeZOIAr0Ap9KYc0pl53lZFQbkYiI\niIiISAaY1po2a+02YNukc1+d8PFXgK/MbGnpk+120j8STncZIiIiIiIi07u59qVGu0eKiIiIiEim\nUGibgqZHioiIiIhIplBom0K228moRtpERERERCQDKLRNQSNtIiIiIiKSKRTappDjToQ2a226SxER\nERERkUucQtsUst0urIVgJJ7uUkRERERE5BKn0DaF7KzE06IpkiIiIiIikm4KbVPIcSduXzcSjqa5\nEhERERERudQptE0h2+0EIKiRNhERERERSTOFtilkZyVCm26wLSIiIiIi6abQNoUct0KbiIiIiIhk\nBoW2KXiToU0bkYiIiIiISLoptE1hbKRtVCNtIiIiIiKSZgptU8jJSuweqdAmIiIiIiLpptA2Ba87\n8bSMaHqkiIiIiIikmULbFMbu0zaq+7SJiIiIiEiaKbRNYWzL/9FwPM2ViIiIiIjIpU6hbQpOh8Ht\ncjAS0UibiIiIiIikl0LbOeS4ndqIRERERERE0k6h7RyysxTaREREREQk/RTaziHb7dTukSIiIiIi\nknYKbeeQneUkqJE2ERERERFJM4W2c8hxOxlRaBMRERERkTRTaDuHbLdL0yNFRERERCTtFNrOITvL\noemRIiIiIiKSdtMKbcaYzcaYJmPMUWPMl9/iug8YY6wxZt3MlZgeOW6X7tMmIiIiIiJpd97QZoxx\nAvcBtwErgI8YY1ZMcZ0P+BLwykwXmQ7ZbicjIY20iYiIiIhIek1npG09cNRa22ytDQMPAlumuO5v\ngb8HgjNYX9qU5rrpGwkTjcXTXYqIiIiIiFzCphPaqoHTE45bkufGGWPWArXW2t/MYG1pVVmYTdxC\nRyCU7lJEREREROQS5nqnX8AY4wC+BXxqGtfeDdwN4Pf7aWxsfKfffsYNDQ3R2NhIV1diPdu2p19k\ncZEzzVXJXDLWYyKpoP6SVFOPSSqpvyTVZmuPTSe0tQK1E45rkufG+IBVQKMxBqAC2GqMudNau2Pi\nF7LW3g/cD7Bu3Trb0NDw9itPkcbGRhoaGqjqCPCtnc/iX7CchtVV6S5L5pCxHhNJBfWXpJp6TFJJ\n/SWpNlt7bDrTI7cDi40x9cYYN3AXsHXsQWvtgLW21FpbZ62tA14G3hTYZpvKAi8Abf2jaa5ERERE\nREQuZecNbdbaKHAP8ChwEHjIWrvfGHOvMebOVBeYLj5vFj6Pi7aBObGvioiIiIiIzFLTWtNmrd0G\nbJt07qvnuLbhnZeVGSoLvZzRSJuIiIiIiKTRtG6ufamqLMjWSJuIiIiIiKSVQttbqCr00jagkTYR\nEREREUkfhba3UFmQTfdQmFA0lu5SRERERETkEqXQ9hYqkjtItmuKpIiIiIiIpIlC21uoKsgG4Ey/\nQpuIiIiIiKSHQttbqCxM3qtN69pERERERCRNFNreQnVhNk6HoblrON2liIiIiIjIJUqh7S14s5ws\n8ft4vaU/3aWIiIiIiMglSqHtPNbUFrL7dD/xuE13KSIiIiIicglSaDuPK2oLCQSjNHdriqSIiIiI\niFx8Cm3nsWZeIQC7T2uKpIiIiIiIXHwKbeexsCyPPI+L3af70l2KiIiIiIhcghTazsPpMFxeU6CR\nNhERERERSQuFtmlYO6+Ig20BBoORdJciIiIiIiKXGIW2abhhSRmxuOWFI93pLkVERERERC4xCm3T\nsHZeIT6vi6ebOtNdioiIiIiIXGIU2qbB5XRww+IyGpu6sFb3axMRERERkYtHoW2aGpaW0RkIcaBt\nMN2liIiIiIjIJUShbZpuXFoGwLa9bWmuRERERERELiUKbdNU7vOyeWUF//7iSQZGtIukiIiIiIhc\nHAptF+BLtywmEIry/eeb012KiIiIiIhcIhTaLsDyynxuW1XBD144wVAomu5yRERERETkEqDQdoHu\nvmEBQ6EoD+9qTXcpIiIiIiJyCVBou0BragtZWZXPf758Utv/i4iIiIhIyim0XSBjDB/fOJ9D7QF2\nnuxLdzkiIiIiIjLHTSu0GWM2G2OajDFHjTFfnuLxzxtj9hpjdhtjnjfGrJj5UjPHljVV+LwuvvPE\nEY22iYiIiIhISp03tBljnMB9wG3ACuAjU4Syn1hrL7PWrgG+DnxrxivNIDluF39661KeP9rN1tfP\npLscERERERGZw6Yz0rYeOGqtbbbWhoEHgS0TL7DWDk44zAXm/PDTxzfOZ3VNAX+1dT//8swxBoO6\nd5uIiIiIiMy86YS2auD0hOOW5LmzGGP+wBhzjMRI2xdnprzM5XQYvv2/1rDE7+Nrvz3Eh//5JfpH\nwukuS0RERERE5hhzvjVZxpgPAputtZ9NHv8usMFae885rv8o8G5r7SeneOxu4G4Av99/5YMPPvgO\ny595Q0ND5OXlXdDn7O2K8t1dIWryHHzhCg8l2drfRc7t7fSYyHSpvyTV1GOSSuovSbVM67FNmzbt\ntNauO9910wltVwN/ba19d/L4KwDW2q+d43oH0GetLXirr7tu3Tq7Y8eO89V30TU2NtLQ0HDBn/fU\noQ6+8JNdOIzh6x+8nNsuq5z54mROeLs9JjId6i9JNfWYpJL6S1It03rMGDOt0DadIaHtwGJjTL0x\nxg3cBWyd9M0WTzh8D3DkQoqdC25a5ueRP7yBRf48vvDTXTx7uCvdJYmIiIiIyBxw3tBmrY0C9wCP\nAgeBh6y1+40x9xpj7kxedo8xZr8xZjfwx8CbpkZeCmqLc/jRp9ez2O/j8z/eydHOQLpLEhERERGR\nWW5ai6+stdustUustQuttX+XPPdVa+3W5MdfstautNausdZustbuT2XRmSzfm8UDv3cV3iwnX/jp\nbkLRGCPhKP/PtoN8V/d1ExERERGRC+RKdwFzkT/fyzc+eDmf+dEO7vje84yEY7T2jwIwHI7y5c3L\ncDhMmqsUEREREZHZQKEtRW5e7ufeLSt5/EAHcWv5xocu57d727n/2WaeONjBDYvLcLscfOjKGhb7\nfekuV0REREREMpRCWwp94uo6PnF13fjxxvoS1tUV8cCLJ/j5zhZC0Rjff/44tywvp6owmw+srWFV\n9VtuuikiIiIiIpcYhbaLyOEwbFlTzZY1iXuT9wyF+M4TR3juSBfPHO7ihy+cYNPSMq5bXMb71lRR\nkudJc8UiIiIiIpJuCm1pVJLn4W/ftwqAwWCEf322mV/tbuXppi6+88RhPn/jQt6/tpr/fPkUr57o\npWFpGe+5rJL5Jbn0DIUoznVjjNbGiYiIiIjMZQptGSLfm8Wf3LqUP7l1KYc7Anxt20G+8WgT33i0\nCYBF5Xl8/ZEmvv5IE0U5WfSNRLhxSRn/+ol1uF0OrLUMh2PkefQjFRERERGZS/QKPwMt8fv44e+t\n51D7INv2trNxQTHXLCylpW+E3+5tp6kjQJ7HxQMvnuAzP9pOWZ6Hl5t7ODMQpGFpGevmF+F2Objj\n8ipicUtjUyeX1RSysCyX7qEwrzT34C/wsmlpebr/qSIiIiIich4KbRlsWUU+yyryx49rinL43A0L\nxo8rCrx867HDFOVmsaa2kPeuruLhXa00NnUB8PVHmohbS/wct4b79LX17DszQP9ImG99eI02QRER\nERERyUAKbbPY529cyN3XLzjrnm9/vnkZ0bilYzDIj185SZbDwZ1rqjhwZpDOQJDCbDerawv5l2eP\n8YMXjlOa58bpMPzOP77AhvoSVtcWsLjcx9NNnQyORvibO1fhzXKw78wAdSW5zC/Jxal7zImIiIiI\nXDQKbbPc5Jt0OxwGt8NQW5zDV25bPn5+yaR7wX3zQ6t5/xU1rJlXSCQa53tPHeHV47388zPNxOIW\nnzfRGu/53nMEozEiscRwndvloLYoG4/LSZbTkJ+dxQ2Ly1g7v5Da4hzKfV6stRxsC/DQjtOEonGW\n+PP49Z42srOc/M2WlSwsy0vxsyIiIiIiMncotF2ijDFct7g0ceCBv3rvSgBGwzGOdQ2xoCyXrkCI\n//3wPhaW5bJ5VSUtfSMc6RzidO8IkVicSCwxovd32w6Of90l/jxC0Tgne0Zwuxx4nA4CoSgLSnM5\nNhLm9u8+xyevqSPP4+LBV0+xdn4RVYXZ/Pr1M6yZV8iC0jz+a+dpPr5hPl+4efFZNR9qH6Qox40/\n30s4GifLabR7poiIiIjMeQptcpZst3N8bdv8Ehc//uyGCY+WTPk5Y2HuSEeAZw9343Y5+Nz1C7jj\n8kryPC5O940yvziH7qEQX/vtIf7tuWbiFjYuKOaZw10Mh6Jcu6iU5450s21vOwvLcvnm44c53DnE\nqd4R8jxOQpE4O072YQwsKM3lZM8ItcU5vP+KavpGIgwGI1gL1los4HY6uP3ySpZV+DjcEaCpPUBh\njpt3Lffz7ScO09I3yp++ewnLKvKJxOI8e7iL4XCMecU5rKktPO/zNBKO4nE5NVVURERERFJOoU3e\nsZqiHGqKcti0tJy7b1j4psfrS3MBKM/38u3/tYY/vGUxo5EYyyryGQlHGQ3HKMnzMBSKMhSMUubz\n8Ec/282v95xh7bwiAsEoQ6Eof/me5QwGo+xp6eeW5X5eau7hm48fJjvLSVFOFsYYjAFjYGAkws92\nnH5TLU6HSUz/9Li4/bvPsbQin4GRMGcGguPXbF5ZQSgao7l7mOsWlTIwGqFnKMwnr6kjFrc8vKuV\nZw53Ul2Yzf9532Vcs7CEpo4A/7Wjhb2t/YSicaoLs6kpymYoFONY5xBXzCtk48ISfB4Xz5yOMLyn\njdsvqxgfKbTWTjlq2Nw1RKnPQ743a6Z+XCIiIiIyyyi0yUU3vyR3/OMct4scd6IN8zyu8fvMffeu\nNXzt/ZeR+xb3nbPW0jcSoTA7601r+0LRGI/u76B3KMSSCh9L/D4OtQX4zd4z3Lm6muWVPn704kl2\nnuqjzOfhb7asor40h2172/mHp49SkutmeWU+v3ithYLsLNwuB5//8U4A/PkePrZhPk8d6uTj33+F\nPI+LoVAUj8vBZdUFFGRn0dQe4KlDnbhdDhaU5vL954/zL882j9f3w/2vcctyPxsXFHOgbZDH9ndg\ngLJ8D36fl/X1xURicf75mWOU5nm4d8sqbl3h51e7W/npq6e4Yl4R71rhZ+28IroCIdwuB3keF41N\nnTgdhhuWlPH0oU76RyJsWlZOmc8z/r27AiGGQ1Gqi7J5+lAnp3pHuHm5n2AkRsdgkPklucTicdxO\nJ/NKcsY/b2A0gjGJewpGYnFcjulPTx0YjTAwEjnr640JRmL89+5WNi4oOas3AGJxy8BoBGstJXme\nN32uiIiIyKVAoU0ykjHmLQPb2DXFue4pH/O4nNy5uuqsc9ct9ryxjg/40i2LJ38aX7zZx903LMDt\ndOBIjso5TCI8PHGwgzxPFlcvLMHpMPz55mX8Zm8bu0/3UVmQzcc3zKcg540RMWvteJ0DIxGOdAYI\nBKN0HNvHcEE9f//bQzxxsAOf18XmVRXkeVx0BoK09o3yvaeOYC1sWVNFU3uAz/94J+U+D52BEPOK\nc/jhC8e5/9lmXA5DNHlPB2+Wg2Ak/qaPAWqLsynMdtM2EKR7KAS8MeoI8H9+88a6xDeeX/jKbcu4\ncn4RD756mv/efYZwLE5pnofe4RCVBdnccXklI+EY+84McKJ7mDsur2J5ZT57WvpZUZXPyqoCWvtH\n+Zut++kZDrOhvpg1tYVUFWazxO9jX+sAD7x4gtb+UYpz3fzjx9aS780iFrfsbR3g208cpiuQqHd5\nZT7+fA+j4Rgrqwq4qq6I8nwP//nyKQKhKOvmF9HUHsDlNLxvTTUFOVmU+TyU+7x0BULsPNlLKBqn\nYWk5BdlZdAaSo6sWnj/aTdtAkK5AiCOdAa6qK+Z9a6r5zhOHWVqRz+dvXPCWAbVnKMTx7mGWVvgY\nDsV48lAHV9UVs8TvIx639AyHcTsdZ/VHuoyEo5zsGWF5Zf75LxYREZGMYMZeWF5s69atszt27EjL\n934rjY2NNDQ0pLsMmcPGemw4FCUat+R5XG9aG9c2MEp3IMxlNQWEo3F+s/cMW3ef4bKaQr540yJG\nIjGeaepiT0s/tcU5hCJxTvWOcNOycoKRGI8f7OCmZeXUl+bS2NTFwbZBAsEo/nwPS/w+fF4Xx7qG\nuXJ+Ecsr8nnqUAdFuW4q8r2c6k1sIvPo/na27W0HIDvLyQeurKYi38vJnhH8+V52n+7n+aPd5Htd\nLPH78Bd4eWx/O5GYHR99HLO8Mp/bV1Xwq92tnO4bJRx9I1CuqS3kU9fU8Y1Hm2jtHz3rebhyfhF3\nXF5JMBLnmcOdjIRjuByG/WcGCSW/Rq7bSWGOm9b+UUpy3YSjcQLJ7+1yGBqWlvPC0W5GIzEgsSby\n3asquP/Z5vHQOibH7aS2KIemjgDwRrC9ZbmfecU5BIIRwrE4i8ryON4zzJMHOxmNxMb/PS6HwcL4\n1y33eegdDhONW9wuB7+7cT69w2EOtQcozM6iOC9R765TfSwqz+OjG+ZTU5TNEwc62HWqn9+9ej5r\n5xUxMBphiT+PgdEIP9t+mh0n+yj3efiDTYuoKszGWsvLzb30j4R5duc+yK/gqroiGpaWY61l58k+\njDHctKycT/7gVZ4/2s3HNsyYUZFKAAAZGklEQVRj09JyeofD9I6E8XldlOV5CASjxK3Fm+XE43LQ\nEQjROxTmrvW1+PO9AOxp6edfnzvOi0e7uWt9LV+8eTEel3P8eYzFLU8lR3E31BezojJ//E2Qyb3e\nORjkV7tbaWofIhiJsWFBMbeuqKCiwDvd/6QAztqcqDMQxJvlPOe04r7hMH/00G4KsrN4/9oaqguz\nqSvJweV0XND3nEmj4RjN3UOsrLqw+2U+8MJxXjney3fuWnPWz+B89rT048/3jv9ML4R+T0oqqb8k\n1TKtx4wxO6216857nULb2TLtBylzz2zpsXjc8ovXWjDG8O6VfnxTvAAOR+O4XW+80O0YDBIIRllY\nlsuJnhFO9AzjMIaNC4rHX1Baa2kfDHKwbZDF5T5qixNTJjsDQZ4+1InPm0WW04HP62JDffGUI1zh\naJz9ZwY40TPMpuTIWddQiLI8D6ORGC8c7SEWt7zc3MMvX2vh+iVlfPa6egZGI/zxQ6/TOxzmvaur\nuKquiFAkzjWLSlhYlofH5cAYwzOHu3j8QDu/f8NCfrWrlf/v6aO4kzU5HYaWvlF8Hhe3rqyg1Oem\nNNfD/JIcdp/uxxi4bVUlzx/t5mjnEP58TyLknurn4d2t5HuzWDuvkEAwSu9IGGthdU0Brx7vHV9b\n6TBQke89a63lsgof7YNB+kci1JXkcKY/CAY+dU0dJ7qHeexAx/i1uW4nw+HYm563Jf48DncM0bC0\njGcOd3Eh//v3eVx8dOM8DIZ/fa6ZPI+Ly2sKeO5IN5C4HcjNy8qZX5LLr/ecoaXvjQBekuumqjCb\ng22DLK/MZ9Oyck71DHOoPcCRziFicUtlgReHMbT2j+IwcM3CUhqWllFTlENnIMjjBzpwOgzXL05M\n/W0fDFJXkstNy8o52TPMvz1/nLqSHApz3Ow82QfAwrJcvvGh1Rjgl6+18sj+duYX59A/GuFU7wge\nl4NAMBHw60tz+dz1C2gfGCU/O4t1dcXsPzNAKBKnssBL/2gEb5aDJX4fi8rzGAnFePFYD3tbB6gp\nyuZjG+bReLiL3+xpo7owm/klObQNBPmPl07SMxyiIDuLd6+soDjXTfdQiO6hMNWF2Sz25/H66X5+\nu6+dQDDK/759OZ+7YQGdgSDfeKSJkUiMj22Yx8rKAvKzXWf999A2MErDNxoJReN8eF0NOW4X+88M\ncO2iUlZWFVCS5yYet5T5PBTmuDmTfFPkyYMdfPPxw5Tmebjvo2tpHwyysCx3PDC29o/yyL52ynwe\ndp3q4/EDHbznsko+f+NCfF4Xf/UfTzLkLaUwO4t9ZwbpGwmzojI/OYXacM+mRayvLx7/772pI8DA\nSIT19cVYCztO9tHY1MmKqnzuuDwxIyIet7ze0s+TBzsZCkUpz/dwsC1AltNw6wo/Bdlu3C4HTofh\nxy+fpHc4zKeuqeP6xaVnPSfRWJzGpi4KcrJYU1uIAV5u7uVA20Byo6kiKgq8Z60jjsTiGDgrtI+9\nwRCOxvmf189w49IySvPOnma+/UQvq2sLqSrwcrAtgD/fQ3Gum5a+UYpy3ePT/d+O3uEwxbluIrE4\nv3ythTW1RSyt8J3z+qOdAcp8Xgqyzz+af6411GOPHWwL8HJzDzcvLz9rynrbwCjbT/Sxvq6YigIv\n/SNh8r1vXp7wTs3k78gHXjhORUE2m1dVzMjXk7kh016HKbS9TZn2g5S5Rz2WXq39oxztHOKGSS/2\n3srkFzlDoShZTnNBIxuQeKE3tkZyskgszoEzg3QMBllWkU91UTa/3nOGweQL4Z9tP01hThZ/cfty\nllfm09I3wrcfP8Ivd7XgNIY/27yU6xeX0fT6Dra8exOvHu9l35lBAFZW5bPzZB/ffKyJ911RzTc/\ntJpjXcMMhaKU5LopynUzOBqheyhEvjcLp8MQjMQIRuIU5WYRiVnu/Z/9PHekm2jcsmVNFX/7vlXk\ne7N4/kg3rxzvoX8kwv/sOUMgGOWahSXcddU8rphXyMvNPTx3pJv2gSDLKn08f6SbI51DVBV4WVLh\n47LqAn7nimoWlOVhreVY1zBbd7fy671tNHcNjz8/C0pzCUXjtPaPUl2YzcqqfJo6ApzsGQHgztVV\ntA8GGRyN8N7VVTgdhv946eT46K3H5WDT0nIOdwboGAjyr59Yx5p5hbx2sp/W/hHuf7aZY13DOAzE\nz/Nr0ekwWGuJW8avf+/qKh7Z14bX5WQoHB0PxNcvLmVVdQGnekd48mAH4Wic4lwPxblZnOodIRiJ\n4/O6uHlZOUOhGE8c7ODqBSXsOzNAKBonx+2kfyQCJIL8+vpidp3uw+10UFmQzavHe7ljdSW/fK0V\nh4FlFfkcbB88byC/bVUFu0/305Z8Y8DlMHzm+nraB4Js29s2fm9Ol8Owdl4R20/2YoDiXA/dQyEq\n8r0EghEW+32U5nk42DZISZ6b9oEgnYEQtywv5+qFpfzg+ePjP4M7Lq+kMxDi1eO943XcvKycHI+L\nV4/30DEYwukweFwORsIxKgu8jIRjDIxGzqo9O8uJz+uiMxDi8poCVtcU8viBDgpzshgORznde/aI\n/WSVBV56hsOU5rpZWJ7Hayf7cDgMG+qLKcpx09QRYF/rAB9ZP49TvSM8d6Sbguwsbl5WzpHOIToD\niX+jtYnnx5/vpbV/dHzN78BoBKfDcOW8Ij59XR1N7UO83NzDpmVleLOc9AyF+fR19RRkJ6798csn\n2X6il56hMKuqCzjZM8yLx3r4xNXzCQSjPLyrFYBbV/j5h4+upak9wNNNncwvySESs2zb28ZThzrJ\n97p47+oqhkJR2pJv6tyzaREW2NvSz5Y11Ty04zQ/eP44X7h5MR/bMI+RcAyPy8Ezh7v42fbTHO4Y\nGp9Cn+U03LLcT2mehx0n+zjYNjj+/C+r9LHrVD8bFxTzjQ+u5nBHgEf3t9M2EOTT19ZzoG2Qpw51\nsrqmEE+Wg56hENWFOfSNhDnWNcQSv4+blpVzzcISjDF0D4XYfryX7qEQp48f5WPvvprRSIxct4va\n4hyeOtTBnpbEGxJL/D7yvS5iyaC/82QfzV3DrKzKZ+OCEv5nTxv1pTkMh2L85a/2AYk3t1471cfp\n3hEKc9z85XuWU1Hg5fvPHSduLauqC/jdq+cTi1usZXx5Rt9wmKNdQywp91GQk0U8bnnuaDc7T/Ti\ncjpYVZ3P6ppCTveNUlOUTWleYgp/zFo6B4P82/PHcTsd3LW+lmUVb0xJP907ws93tvBScw8fWFvN\nh66sxeEwNLUHaBsYHf9/vNvp5LKaAqKxOC19o8Rsor7OQJBXmnuZV5zDrSv95LhdPH2ok31nBvjA\n2hqeOtTJL15r4d0rK/j4xvkUZGfR0jdC/0hkfOaDtZajnUNUFWaT43bSlfz/P0DbQJB5xTnjvwvG\n3tDsDARpbOriuSPdbD/eyw1LSrl3yyq8WW/8LjzaGaAzECI7y8kvX2ul3Ofh7hsX4HE5GQpFOdkz\nzPKK/DeF/WAkdtbXgcTv3q6hEIFglHA0TjgaT84Q8Lzp9/dIOEpjUxdtA0E21BeP74Q+1dfOtNdh\nCm1vU6b9IGXuUY/JTDqaHKkaexf+rfrrTP8o/nzv275VRTASoysQoqYoe8rAG4rGCEXjb7nbqbWW\nYCROtvv8gbdtYJS+4Qg+r4uaomyshRM9w8wvyR0PTvvPDOJ0mCnX6A0GI/zw+RNUFnjZfFkF+d4s\nrLWEovE3vTiIxOIc7giwoDSPzkCQ11sGuKy6gHyvi/bBIIU5bkbDUQ61BzjUllg7ecOSMlZW5fOX\nD+/jv3a2sKIynwd/fyMel4OWvlEMsKAs76zv4TBm/PkPRWO09SdeHDmSozpf/uUemtoDLK3wJaa/\nFmTT2NRJa/8oO070sf1EL5fXFHCiZ4Tj3cN8+tp6/uL2ZTzw4gk2LihhVXUBAyMRjvcM0zscwulw\n0DEYpH8kTHVhDg4DXreThiVltA8G2ba3nVVV+fzgheM8ur+D4lw377msks9cV08wGhu/N+ah9kG2\n7W3nUNsgSz39/PGHb56yB0bDMX744nH+6eljBEJR1s4r5K718zjTP8r3njyCz5vFn21eyh2XV/HA\nCyd44MXj+LxZrKjM59aVfm5alhg5D4Si45se7WnpJxy1BCOJAHf94lLyvC5++Vor/9R4jLaBUTYt\nLScUjROKxvjUNXVYCwfbA2AtK6ryWV9fQkvfCC8d6+Fg2yBlPg+t/aMc7hjiqrpirLVsP9HLcChG\nRYGXBaW5PLy7FYcx/OmtS3nuSBeH2gOsrMqnqiCbeSU5XDm/iMf2d3CyZ5h3rfDTFQjR0jfKqpoC\nOgaC/PfrreMBsr40l+PdE96EKMtNBIzdZwiEoiyvzKc4N4s9pwfIdjtZV1c0Pj39izctwuEwfOeJ\nI1y/uJQdJ/rGp3tDYhT8s9cvYG/rAC8c7abM56GiwEvbwOiUAXZReR5HO4fedH5BaS7r6opYXVvI\nVXXF/OjFEzx7pIveZJi8aVk5a2oL+fErpzjSEWDjghJ+8uqp8enhY5uJtQ8m3ghYXpnPsa4h4nFL\nYU5ihDnH7WR+SS7HuoYIR+PUFmcDvGXQnqpeYzjrjYmxADzZjUvKyM5y8sj+dhaV53H1ghK2n+jl\nUHsAp8OQ63aSn51FS98opXluBkYjZDkdfHhdLbtP97P7dD+QCLBLK3x0DIbG11lP5jBQl7wlUWzC\nWvN4HMKxOFvWVHF5TSFPHOjgpeYejIGaomxO945S5vPg87hontAjY+64vJL9ZwbP6p+pvvfYm01j\nz01dSQ4nekYo83n44JU1/OD544SicSryvXz2+nr2nxnk4V2tuJ0Ocj1O+pJvDo19/uraQjbWF/PD\nF0/wruV+bl3p589/sYdgJE6Zz8Nl1QU8daiTygIv0bhldU0Ba2oL+fYTR8b//W6Xg3A0zvySHNxO\nB83dw8Tilg31xfzZ5mUU5mSRneXkoR2nue/po2xcUMKV84v41a5WgpE4wWhs/E2riXweF4v8eSwu\nz6OmKIehUJRfvtZC91AYSLxJ9/9+aDW9w2Ee3tXK7tP9XF5TwPuvqOZT19Zn3Oswhba3KdN+kDL3\nqMckldRfF18sbvnVrlYalpZdtF1Og5HEqNxNy8rHd+B9J8amLft93vNOd5tOj/UNh2ntH2VlVf54\nuDvcEaA0z3PODaTejljcEom9OYTPhH2tidHOK+cXva3Pj8TiPH2ok6rC7MRoa88IDge09o3yf/3n\na4yEo2xeWcHnblgwPjU1FrcYwOEwPLyrhYGRCJ+8pg5jDN994gjffuIwyyp8fP9TVzEUjOLNcuDP\n90757w9GYvzitRbyPC7W1Bby7y+dZFF5HnddVctjBzpo7hrG53URjMRYUJZLw5LyC57quK91gGcO\nd7GmtpB1dYnn6devt1FbnMP6+mLC0TgOk5h6Gowk1iSPffzrPW08sq+NXI+LxeV5XLuolOqibB55\n+gWyKhbj87o42TPCYwc6uHWFn7uuqmX7iT5a+kbGp+Iu9fvYuKCY4lw3O072sadlgNsvq+CV5l6e\nPdLFX713JXkeF03tAZZV+HAkR46+tu0gMWv501uXUpjj5vkj3fzopRMsKMulpXeU3+xtY0FZLh9Y\nW8MSv4+Xm3s40jlEaa6bG5eWsXlVBdbCy809HO4IMK84h/1nBtl/ZpCVVfnkeVxY4P1rq8lyOPj+\n88e5/7lmwtE4C8pyed+aaj5wZQ1VBV62vn6GZw930z8S5tpFpSyr8HGoPUBNUTa7T/fzL882s6gs\nj09cM398ym2+N4sr64o40hHg5eZeRsJRVlUVsKq6gB++cIL6slw+vmEee1sH+LOf7+FQe4DrF5fy\n3tVV/PfuVl44mgiNv3/DQuLWMjgaYWmFj5FwjGjMkutx8o+Nx+gdDnPNwhJeau7B2sQa9L/7nVWs\nqEz8d/3EgQ5+8uopCrKzeOJgB4FglFuWl/O7V9fROxzipqV+tp/o5f5nmynMyWKJ30dBdhbfffLI\nWeveARqWlrHrVD8DoxGuXVRCdWE2ToeDJf48inPdeFwOXA4HbYNBjnYkptaPjQw7HYllGH+waRG1\nRTl8/sc72Z+cabK8Mp/rF5fy4rFuSnI9/OjT6zPu96RC29uUaT9ImXvUY5JK6i9JNfXYOxeKxojF\n7QUFbmstTxzsZH1dcUbsRJsqmdBfA6MR8r2uaU+hn46uQIhwLHEf1wsxEo7idTnf9trBcDTOzpN9\nrK8vHh/l336iF4eBK+cXn/Pz+obDdAQS0/Ubmzp5ubmXP7xl8TnfIOkbDrPzZB83LTt/+O8YDLL7\ndD/BSIzRcIx5JTlcs7CUQDDCYDB6Qc/RVLcgGhiJ8IvXWrhmUclZ01JHwzGy3c6M6LGJphvatOW/\niIiIyEV0oethIXH7mHet8KegGplsOhu6XKiJ90u9EO90JN3tcnD1wpKzzl1Vd+6wNqYoud4ZoGFp\nOQ1Ly897/S3T7E9/vpd3r3zz5jA+b9aUm569lawpdv0tyMni09fVv+n8dKblZ7L07W8sIiIiIiIi\n56XQJiIiIiIiksEU2kRERERERDLYtEKbMWazMabJGHPUGPPlKR7/Y2PMAWPMHmPMk8aY+TNfqoiI\niIiIyKXnvKHNGOME7gNuA1YAHzHGrJh02S5gnbX2cuDnwNdnulAREREREZFL0XRG2tYDR621zdba\nMPAgsGXiBdbap621I8nDl4GamS1TRERERETk0jSd0FYNnJ5w3JI8dy6fAX77TooSERERERGRhBm9\nT5sx5uPAOuDGczx+N3A3gN/vp7GxcSa//YwYGhrKyLpk7lCPSSqpvyTV1GOSSuovSbXZ2mPTCW2t\nQO2E45rkubMYY24B/jdwo7U2NNUXstbeD9yfvL5r06ZNJy+44tQrBbrTXYTMaeoxSSX1l6SaekxS\nSf0lqZZpPTatDRyNtfatLzDGBRwGbiYR1rYDH7XW7p9wzRUkNiDZbK098nYrzgTGmB3W2nXprkPm\nLvWYpJL6S1JNPSappP6SVJutPXbeNW3W2ihwD/AocBB4yFq73xhzrzHmzuRl3wDygP8yxuw2xmxN\nWcUiIiIiIiKXkGmtabPWbgO2TTr31Qkf3zLDdYmIiIiIiAjTvLn2Jeb+dBcgc556TFJJ/SWpph6T\nVFJ/SarNyh4775o2ERERERERSR+NtImIiIiIiGQwhbYJjDGbjTFNxpijxpgvp7semX2MMT8wxnQa\nY/ZNOFdsjHncGHMk+XdR8rwxxnwv2W97jDFr01e5zAbGmFpjzNPGmAPGmP3GmC8lz6vHZEYYY7zG\nmFeNMa8ne+xvkufrjTGvJHvpZ8YYd/K8J3l8NPl4XTrrl9nBGOM0xuwyxvw6eaz+khljjDlhjNmb\n3BxxR/LcrP89qdCWZIxxAvcBtwErgI8YY1aktyqZhR4ANk8692XgSWvtYuDJ5DEkem1x8s/dwD9d\npBpl9ooCf2KtXQFsBP4g+f8p9ZjMlBBwk7V2NbAG2GyM2Qj8PfBta+0ioA/4TPL6zwB9yfPfTl4n\ncj5fIrEj+Rj1l8y0TdbaNRO29p/1vycV2t6wHjhqrW221oaBB4Etaa5JZhlr7bNA76TTW4AfJT/+\nEfC+Cef/3Sa8DBQaYyovTqUyG1lr26y1ryU/DpB40VONekxmSLJXhpKHWck/FriJxP1Y4c09NtZ7\nPwduNsaYi1SuzELGmBrgPcC/JY8N6i9JvVn/e1Kh7Q3VwOkJxy3JcyLvlN9a25b8uB3wJz9Wz8nb\nlpwmdAXwCuoxmUHJqWu7gU7gceAY0J+8byuc3UfjPZZ8fAAoubgVyyzzHeDPgHjyuAT1l8wsCzxm\njNlpjLk7eW7W/56c1n3aRGRmWGutMUZbtso7YozJA34B/KG1dnDiG8/qMXmnrLUxYI0xphB4GFiW\n5pJkjjDG3AF0Wmt3GmMa0l2PzFnXWWtbjTHlwOPGmEMTH5ytvyc10vaGVqB2wnFN8pzIO9UxNtSe\n/LszeV49JxfMGJNFIrD9p7X2l8nT6jGZcdbafuBp4GoSU4bG3uid2EfjPZZ8vADoucilyuxxLXCn\nMeYEiWUoNwHfRf0lM8ha25r8u5PEG0/rmQO/JxXa3rAdWJzcwcgN3AVsTXNNMjdsBT6Z/PiTwH9P\nOP+J5M5FG4GBCUP3Im+SXMvxfeCgtfZbEx5Sj8mMMMaUJUfYMMZkA+8isXbyaeCDycsm99hY730Q\neMrqBrByDtbar1hra6y1dSReZz1lrf0Y6i+ZIcaYXGOMb+xj4FZgH3Pg96Rurj2BMeZ2EnOtncAP\nrLV/l+aSZJYxxvwUaABKgQ7gr4BfAQ8B84CTwIettb3JF+D/QGK3yRHg96y1O9JRt8wOxpjrgOeA\nvbyxHuQvSKxrU4/JO2aMuZzEIn0niTd2H7LW3muMWUBiZKQY2AV83FobMsZ4gf8gsb6yF7jLWtuc\nnuplNklOj/xTa+0d6i+ZKcleejh56AJ+Yq39O2NMCbP896RCm4iIiIiISAbT9EgREREREZEMptAm\nIiIiIiKSwRTaREREREREMphCm4iIiIiISAZTaBMREREREclgCm0iIiIiIiIZTKFNREREREQkgym0\niYiIiIiIZLD/H4Pykoike9SIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}